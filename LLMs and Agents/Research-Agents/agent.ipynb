{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage, trim_messages\n",
    "from langchain_core.tools import tool, ToolException, InjectedToolArg\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun, HumanInputRun\n",
    "from langgraph.graph import StateGraph,START,END, add_messages, MessagesState\n",
    "#from langgraph.prebuilt import create_react_agent, ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import wikipedia\n",
    "import uuid\n",
    "import operator\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "#from google.colab import userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporating tools into LangGraph agents\n",
    "An AI tool is a component that enhances the default functionalities of an AI agent, allowing it to perform a specific task or access external information. For example, you can use tools to access the web, connect to an external database, book a flight, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arxiv_search': StructuredTool(name='arxiv_search', description='Returns the information about research papers from arxiv', args_schema=<class '__main__.ArticleTopic'>, func=<function arxiv_search at 0x13afb8cc0>), 'wikipedia_search': StructuredTool(name='wikipedia_search', description='Returns the summary of wikipedia page of the passed topic', args_schema=<class '__main__.WikipediaTopic'>, func=<function wikipedia_search at 0x13afb8d60>)}\n",
      "bound=ChatVertexAI(project='hallowed-span-459710-s1', model_name='gemini-2.0-flash-001', full_model_name='projects/hallowed-span-459710-s1/locations/us-central1/publishers/google/models/gemini-2.0-flash-001', client_options=ClientOptions: {'api_endpoint': 'us-central1-aiplatform.googleapis.com', 'client_cert_source': None, 'client_encrypted_cert_source': None, 'quota_project_id': None, 'credentials_file': None, 'scopes': None, 'api_key': None, 'api_audience': None, 'universe_domain': None}, default_metadata=(), temperature=0.0, max_output_tokens=2048, model_family=<GoogleModelFamily.GEMINI_ADVANCED: '2'>, model_kwargs={}) kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv_search', 'description': 'Returns the information about research papers from arxiv', 'parameters': {'properties': {'topic': {'description': 'The topic of the article to search on arxiv.', 'type': 'string'}}, 'required': ['topic'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia_search', 'description': 'Returns the summary of wikipedia page of the passed topic', 'parameters': {'properties': {'topic': {'description': 'The wikipedia article topic to search', 'type': 'string'}}, 'required': ['topic'], 'type': 'object'}}}]} config={} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "# This defines a simple state that stores a list of any type of LangChain message, such as ToolMessage, AIMessage, HumanMessage, etc.\n",
    "# The operator.add operator will add new messages to the list instead of overwriting existing ones. \n",
    "# This defines the agent's memory as a list of messages (AnyMessage), where each interaction (user input, \n",
    "# tool results, LLM responses) is stored sequentially.\n",
    "# The agent remembers the entire conversation history, enabling multi-step reasoning (e.g., refining searches based on prior results\n",
    "# Example:\n",
    "# Initial state: messages = [HumanMessage(\"Find hotels in Paris\")]\n",
    "\n",
    "# After a tool call: messages = [HumanMessage(...), ToolMessage(hotel_data)]\n",
    "\n",
    "# Final state: messages = [HumanMessage(...), ToolMessage(...), AIMessage(\"Here are 5 hotels...\")]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "# Now add a node to the LangGraph\n",
    "# The run_llm() function accepts an object of the State class that we defined before. When we add the run_llm() function \n",
    "# to a LangGraph node, LangGraph will automatically pass the agent’s state to the run_llm() function. \n",
    "# LangGraph automatically passes the current State (with all past messages) to this function\n",
    "\n",
    "def run_llm(state: State):\n",
    "    messages = state['messages']    # Get conversation history\n",
    "    message = model.invoke(messages)  # Call LLM (e.g., Gemini)\n",
    "    print(messages)\n",
    "    return {'messages': [message]}     # Append response to state\n",
    "\n",
    "# TOOL NO.1 - We will use the LangChain ArXiv tool wrapper to create a tool that returns research papers based on user queries. \n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())\n",
    "def get_arxiv_data(query):\n",
    "    data = arxiv_tool.invoke(query)  # Takes a search query as input\n",
    "    return data                      # Returns raw data from arXiv a list of papers/metadata\n",
    "\n",
    "# The tool description is critical because the LLM agent selects a tool based on its description. \n",
    "class ArticleTopic(BaseModel):\n",
    "    topic: str = Field(description=\"The topic of the article to search on arxiv.\")\n",
    "\n",
    "# Registered as a LangChain tool with @tool decorator\n",
    "# BaseModel is from Pydantic (a data validation library). It lets us define structured data schemas with type hints and automatic validation\n",
    "@tool (args_schema = ArticleTopic)    # Enforces structured input of a user query\n",
    "def arxiv_search(topic: str) -> str:\n",
    "  \"\"\"Returns the information about research papers from arxiv\"\"\"\n",
    "  return get_arxiv_data(topic)\n",
    "\n",
    "\n",
    "# TOOL NO.2 - The tool uses the Python Wikipedia library to return Wikipedia article summaries based on user queries.\n",
    "def get_wiki_data(topic):\n",
    "    data = wikipedia.summary(topic)\n",
    "    return data\n",
    "\n",
    "class WikipediaTopic(BaseModel):\n",
    "    topic: str = Field(description=\"The wikipedia article topic to search\")\n",
    "\n",
    "@tool (args_schema = WikipediaTopic)\n",
    "def wikipedia_search(topic: str) -> str:\n",
    "  \"\"\"Returns the summary of wikipedia page of the passed topic\"\"\"\n",
    "  return get_wiki_data(topic)\n",
    "\n",
    "# LLM (Gemini) to use\n",
    "model = ChatVertexAI(\n",
    "            model_name=\"gemini-2.0-flash-001\",\n",
    "            temperature=0, \n",
    "            max_output_tokens=2048, \n",
    "            project= \"hallowed-span-459710-s1\" ,\n",
    "            location= \"us-central1\"  \n",
    "        )\n",
    "\n",
    "# Now bind the tools to the llm\n",
    "# bind.tools embeds the tool schemas (names, descriptions, parameters) into the LLM's context\n",
    "# e.g teaches Gemini that arxiv_search exists → \"For searching research papers on arXiv\", wikipedia_search exists → \"For getting Wikipedia summaries\"\n",
    "tools = [arxiv_search, wikipedia_search]\n",
    "tool_names = {t.name: t for t in tools}\n",
    "print(tool_names)\n",
    "model = model.bind_tools(tools)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, define a function that executes whenever an agent decides to call one or more tools.\n",
    "# The execute_tools function above will be added to a LangGraph agent’s node, automatically receiving the agent’s current state.\n",
    "#  We will only call the execute_tools() function if the agent decides to use one or both of these tools. \n",
    "def execute_tools(state: State):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "\n",
    "      if not t['name'] in tool_names:\n",
    "        result = \"Error: There's no such tool, please try again\"\n",
    "      else:\n",
    "        result = tool_names[t['name']].invoke(t['args'])\n",
    "\n",
    "        results.append(\n",
    "          ToolMessage(\n",
    "            tool_call_id=t['id'],\n",
    "            name=t['name'],\n",
    "            content=str(result)\n",
    "          )\n",
    "        )\n",
    "\n",
    "    return {'messages': results}\n",
    "\n",
    "#  define a function that checks whether the agent's latest state contains tool calls.\n",
    "def tool_exists(state: State):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "# now build graph with tool nodes and edges\n",
    "graph_builder=StateGraph(State)\n",
    "graph_builder.add_node(\"llm\", run_llm)\n",
    "graph_builder.add_node(\"tools\", execute_tools)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"llm\",\n",
    "     tool_exists,\n",
    "    {True: \"tools\", False: END}\n",
    "    )\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"llm\")\n",
    "graph_builder.set_entry_point(\"llm\")\n",
    "graph=graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Give me the latest research paper on attention is all you need', additional_kwargs={}, response_metadata={})]\n",
      "[HumanMessage(content='Give me the latest research paper on attention is all you need', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'arxiv_search', 'arguments': '{\"topic\": \"attention is all you need\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 60, 'candidates_token_count': 9, 'total_token_count': 69, 'prompt_tokens_details': [{'modality': 1, 'token_count': 60}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 9}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.007037736475467682, 'model_name': 'gemini-2.0-flash-001'}, id='run--1abf516a-f3fc-46d3-b6aa-18d281fc2503-0', tool_calls=[{'name': 'arxiv_search', 'args': {'topic': 'attention is all you need'}, 'id': '8bc95912-3918-4286-b020-19b58f9d1ddf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 60, 'output_tokens': 9, 'total_tokens': 69}), ToolMessage(content=\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time on the performance of\\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\\ndecreases performance but leads to the best speedups alongside dropping entire\\nlayers. For example, removing 33\\\\% of attention layers in a 13B Llama2 model\\nresults in a 1.8\\\\% drop in average performance over the OpenLLM benchmark. We\\nalso observe that skipping layers except the latter layers reduces performances\\nfor more layers skipped, except for skipping the attention layers.\\n\\nPublished: 2021-07-16\\nTitle: All the attention you need: Global-local, spatial-channel attention for image retrieval\\nAuthors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\\nSummary: We address representation learning for large-scale instance-level image\\nretrieval. Apart from backbone, training pipelines and loss functions, popular\\napproaches have focused on different spatial pooling and attention mechanisms,\\nwhich are at the core of learning a powerful global image representation. There\\nare different forms of attention according to the interaction of elements of\\nthe feature tensor (local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses only one or two\\nforms of attention and applies it to different problems like classification,\\ndetection or retrieval.\\n  We present global-local attention module (GLAM), which is attached at the end\\nof a backbone network and incorporates all four forms of attention: local and\\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\\npooling, we learn a powerful embedding for image retrieval. Focusing on global\\ndescriptors, we provide empirical evidence of the interaction of all forms of\\nattention and improve the state of the art on standard benchmarks.\\n\\nPublished: 2023-06-02\\nTitle: RITA: Group Attention is All You Need for Timeseries Analytics\\nAuthors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li\\nSummary: Timeseries analytics is of great importance in many real-world applications.\\nRecently, the Transformer model, popular in natural language processing, has\\nbeen leveraged to learn high quality feature embeddings from timeseries, core\\nto the performance of various timeseries analytics tasks. However, the\\nquadratic time and space complexities limit Transformers' scalability,\\nespecially for long timeseries. To address these issues, we develop a\\ntimeseries analytics tool, RITA, which uses a novel attention mechanism, named\\ngroup attention, to address this scalability issue. Group attention dynamically\\nclusters the objects based on their similarity into a small number of groups\\nand approximately computes the attention at the coarse group granularity. It\\nthus significantly reduces the time and space complexity, yet provides a\\ntheoretical guarantee on the quality of the computed attention. The dynamic\\nscheduler of RITA continuously adapts the number of groups and the batch size\\nin the training process, ensuring group attention always uses the fewest groups\\nneeded to meet the approximation quality requirement. Extensive experiments on\\nvarious timeseries datasets and analytics tasks demonstrate that RITA\\noutperforms the state-of-the-art in accuracy and is significantly faster --\\nwith speedups of up to 63X.\", name='arxiv_search', tool_call_id='8bc95912-3918-4286-b020-19b58f9d1ddf')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Give me the latest research paper on attention is all you need', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'arxiv_search', 'arguments': '{\"topic\": \"attention is all you need\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 60, 'candidates_token_count': 9, 'total_token_count': 69, 'prompt_tokens_details': [{'modality': 1, 'token_count': 60}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 9}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.007037736475467682, 'model_name': 'gemini-2.0-flash-001'}, id='run--1abf516a-f3fc-46d3-b6aa-18d281fc2503-0', tool_calls=[{'name': 'arxiv_search', 'args': {'topic': 'attention is all you need'}, 'id': '8bc95912-3918-4286-b020-19b58f9d1ddf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 60, 'output_tokens': 9, 'total_tokens': 69}),\n",
       "  ToolMessage(content=\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time on the performance of\\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\\ndecreases performance but leads to the best speedups alongside dropping entire\\nlayers. For example, removing 33\\\\% of attention layers in a 13B Llama2 model\\nresults in a 1.8\\\\% drop in average performance over the OpenLLM benchmark. We\\nalso observe that skipping layers except the latter layers reduces performances\\nfor more layers skipped, except for skipping the attention layers.\\n\\nPublished: 2021-07-16\\nTitle: All the attention you need: Global-local, spatial-channel attention for image retrieval\\nAuthors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\\nSummary: We address representation learning for large-scale instance-level image\\nretrieval. Apart from backbone, training pipelines and loss functions, popular\\napproaches have focused on different spatial pooling and attention mechanisms,\\nwhich are at the core of learning a powerful global image representation. There\\nare different forms of attention according to the interaction of elements of\\nthe feature tensor (local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses only one or two\\nforms of attention and applies it to different problems like classification,\\ndetection or retrieval.\\n  We present global-local attention module (GLAM), which is attached at the end\\nof a backbone network and incorporates all four forms of attention: local and\\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\\npooling, we learn a powerful embedding for image retrieval. Focusing on global\\ndescriptors, we provide empirical evidence of the interaction of all forms of\\nattention and improve the state of the art on standard benchmarks.\\n\\nPublished: 2023-06-02\\nTitle: RITA: Group Attention is All You Need for Timeseries Analytics\\nAuthors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li\\nSummary: Timeseries analytics is of great importance in many real-world applications.\\nRecently, the Transformer model, popular in natural language processing, has\\nbeen leveraged to learn high quality feature embeddings from timeseries, core\\nto the performance of various timeseries analytics tasks. However, the\\nquadratic time and space complexities limit Transformers' scalability,\\nespecially for long timeseries. To address these issues, we develop a\\ntimeseries analytics tool, RITA, which uses a novel attention mechanism, named\\ngroup attention, to address this scalability issue. Group attention dynamically\\nclusters the objects based on their similarity into a small number of groups\\nand approximately computes the attention at the coarse group granularity. It\\nthus significantly reduces the time and space complexity, yet provides a\\ntheoretical guarantee on the quality of the computed attention. The dynamic\\nscheduler of RITA continuously adapts the number of groups and the batch size\\nin the training process, ensuring group attention always uses the fewest groups\\nneeded to meet the approximation quality requirement. Extensive experiments on\\nvarious timeseries datasets and analytics tasks demonstrate that RITA\\noutperforms the state-of-the-art in accuracy and is significantly faster --\\nwith speedups of up to 63X.\", name='arxiv_search', tool_call_id='8bc95912-3918-4286-b020-19b58f9d1ddf'),\n",
       "  AIMessage(content='Here are some recent research papers related to \"attention is all you need\":\\n\\n*   **Attention Is All You Need But You Don\\'t Need All Of It For Inference of Large Language Models** (2024-07-22) by Tyukin et al. This paper investigates the effect of dropping MLP and attention layers at inference time on the performance of Llama-v2 models, finding that dropping deeper attention layers only marginally decreases performance but leads to the best speedups.\\n*   **RITA: Group Attention is All You Need for Timeseries Analytics** (2023-06-02) by Liang et al. This paper introduces RITA, a timeseries analytics tool that uses a novel group attention mechanism to address the scalability issue of Transformers for long timeseries.\\n*   **All the attention you need: Global-local, spatial-channel attention for image retrieval** (2021-07-16) by Song et al. This paper presents a global-local attention module (GLAM) that incorporates all four forms of attention: local and global, spatial and channel, to learn a powerful embedding for image retrieval.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 867, 'candidates_token_count': 242, 'total_token_count': 1109, 'prompt_tokens_details': [{'modality': 1, 'token_count': 867}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 242}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.014432029290632769, 'model_name': 'gemini-2.0-flash-001'}, id='run--cf3c459e-ae0e-42a7-810d-a16eee2b8cf7-0', usage_metadata={'input_tokens': 867, 'output_tokens': 242, 'total_tokens': 1109})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The agent we have decides if it will need the tools we defined to answer a user query:\n",
    "# below is an exmaple where it will need a tool (arxiv)\n",
    "messages = [HumanMessage(content=\"Give me the latest research paper on attention is all you need\")]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='How many months are in a year?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How many months are in a year?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='There are 12 months in a year.\\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 56, 'candidates_token_count': 11, 'total_token_count': 67, 'prompt_tokens_details': [{'modality': 1, 'token_count': 56}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 11}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -1.3806433840231461e-05, 'model_name': 'gemini-2.0-flash-001'}, id='run--9e637720-629f-474e-96ad-0fe66871a195-0', usage_metadata={'input_tokens': 56, 'output_tokens': 11, 'total_tokens': 67})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When the agent does not need a tool, it will return a response from the LLM (Gemini), e.g this query\n",
    "messages = [HumanMessage(content=\"How many months are in a year?\")]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is Christiano Ronaldo\n",
      "[HumanMessage(content='Who is Christiano Ronaldo', additional_kwargs={}, response_metadata={})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia_search (34a4867d-c5df-4b90-9145-cf23cd3745d5)\n",
      " Call ID: 34a4867d-c5df-4b90-9145-cf23cd3745d5\n",
      "  Args:\n",
      "    topic: Cristiano Ronaldo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia_search\n",
      "\n",
      "Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu] ; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al-Nassr and the Portugal national team. Nicknamed CR7, he is widely regarded as one of the greatest players of all time, and has won numerous individual accolades throughout his professional footballing career, including five Ballon d'Or awards, a record three UEFA Men's Player of the Year Awards, four European Golden Shoes, and was named five times the world's best player by FIFA. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues and the UEFA European Championship. Ronaldo holds the records for most goals (140) and assists (42) in the Champions League, goals (14) and assists (8) in the European Championship, and most international appearances (219) and international goals (136). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 900 official senior career goals for club and country, making him the top goalscorer of all time.\n",
      "Ronaldo began his senior career with Sporting CP, before signing with Manchester United in 2003, winning the FA Cup in his first season. He went on to become a star player at United, as they won three consecutive Premier League titles, the Champions League and the FIFA Club World Cup; his 2007–08 season earned him his first Ballon d'Or, aged 23. Ronaldo was the subject of the then-most expensive association football transfer when he signed for Real Madrid in 2009 in a transfer worth €94 million (£80 million). He was integral to Madrid becoming a dominant force again, as they won four Champions Leagues from 2014 to 2018, including La Décima. He won back-to-back Ballon d'Or awards in 2013 and 2014, and again in 2016 and 2017, and was runner-up three times behind Lionel Messi, his perceived career rival. He also became the club's all-time top goalscorer and finished as the Champions League's top scorer for six consecutive seasons between 2012 and 2018. With Madrid, Ronaldo's additional titles include two La Liga titles, including a record-breaking title win in 2011-12, and two Copas del Rey. In 2018, following issues with the Madrid hierarchy, Ronaldo made a surprise transfer to Juventus in a transfer worth an initial €100 million (£88 million). He won several trophies in Italy, including two Serie A titles and a Coppa Italia, and broke several records for Juventus. He returned to United in 2021; despite a collectively disappointing season, Ronaldo's individual performances earned him being included in the PFA Team of the Year at 37 years old. His contract was terminated in 2022 due to a fall out with the newly appointed manager, and in 2023 he signed for Al-Nassr, a move that has since been widely credited for revolutionising football in Saudi Arabia.\n",
      "Ronaldo made his international debut for Portugal in 2003 at the age of 18 and has earned more than 200 caps, making him history's most-capped male player. Ronaldo has played in eleven major tournaments and scored in ten; he scored his first international goal at Euro 2004, where he helped Portugal reach the final and subsequently made the team of the tournament. In the 2006 FIFA World Cup, his first World Cup, he was a focal part to Portugal ultimately finishing in fourth place. He assumed captaincy of the national team in July 2008 ahead of Euro 2008; four years later, at Euro 2012, he was named to the team of the tournament. In 2015, Ronaldo was named the best Portuguese player of all time by the Portuguese Football Federation. The following year, he led Portugal to their first major tournament title at Euro 2016, being named in the team of the tournament for the third time and receiving the Silver Boot as the second-highest goalscorer of the tournament. This achievement saw him receive his fourth Ballon d'Or. In 2018, Ronaldo had his most prolific World Cup campaign and was voted in the Fan Dream Team. He led his country to victory in the inaugural UEFA Nations League in 2019, receiving the top scorer award in the finals, and also received the Golden Boot as top scorer of Euro 2020. In the 2022 World Cup, he became the first player to score at five World Cups.\n",
      "\n",
      "One of the world's most marketable and famous athletes, Ronaldo was ranked the world's highest-paid athlete by Forbes in 2016, 2017, 2023, and 2024 and the world's most famous athlete by ESPN from 2016 to 2019. He is the first footballer and the third sportsman to earn US$1 billion in his career. Time included him on their list of the 100 most influential people in the world in 2014. Ronaldo is the most popular sportsperson on social media: he counts over 1 billion total followers across Facebook, Twitter, YouTube and Instagram, making him the first person to achieve that feat. Ronaldo was named in the UEFA Ultimate Team of the Year in 2015, the All-time UEFA Euro XI in 2016, and the Ballon d'Or Dream Team in 2020. In recognition of his record-breaking goalscoring success, he received special awards for Outstanding Career Achievement by FIFA in 2021 and Champions League All-Time Top Scorer by UEFA in 2024.\n",
      "\n",
      "\n",
      "[HumanMessage(content='Who is Christiano Ronaldo', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'wikipedia_search', 'arguments': '{\"topic\": \"Cristiano Ronaldo\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 53, 'candidates_token_count': 6, 'total_token_count': 59, 'prompt_tokens_details': [{'modality': 1, 'token_count': 53}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 6}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.025192509094874065, 'model_name': 'gemini-2.0-flash-001'}, id='run--c195f265-a35c-40c2-8698-a18c8252cd51-0', tool_calls=[{'name': 'wikipedia_search', 'args': {'topic': 'Cristiano Ronaldo'}, 'id': '34a4867d-c5df-4b90-9145-cf23cd3745d5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 53, 'output_tokens': 6, 'total_tokens': 59}), ToolMessage(content=\"Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu] ; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al-Nassr and the Portugal national team. Nicknamed CR7, he is widely regarded as one of the greatest players of all time, and has won numerous individual accolades throughout his professional footballing career, including five Ballon d'Or awards, a record three UEFA Men's Player of the Year Awards, four European Golden Shoes, and was named five times the world's best player by FIFA. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues and the UEFA European Championship. Ronaldo holds the records for most goals (140) and assists (42) in the Champions League, goals (14) and assists (8) in the European Championship, and most international appearances (219) and international goals (136). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 900 official senior career goals for club and country, making him the top goalscorer of all time.\\nRonaldo began his senior career with Sporting CP, before signing with Manchester United in 2003, winning the FA Cup in his first season. He went on to become a star player at United, as they won three consecutive Premier League titles, the Champions League and the FIFA Club World Cup; his 2007–08 season earned him his first Ballon d'Or, aged 23. Ronaldo was the subject of the then-most expensive association football transfer when he signed for Real Madrid in 2009 in a transfer worth €94 million (£80 million). He was integral to Madrid becoming a dominant force again, as they won four Champions Leagues from 2014 to 2018, including La Décima. He won back-to-back Ballon d'Or awards in 2013 and 2014, and again in 2016 and 2017, and was runner-up three times behind Lionel Messi, his perceived career rival. He also became the club's all-time top goalscorer and finished as the Champions League's top scorer for six consecutive seasons between 2012 and 2018. With Madrid, Ronaldo's additional titles include two La Liga titles, including a record-breaking title win in 2011-12, and two Copas del Rey. In 2018, following issues with the Madrid hierarchy, Ronaldo made a surprise transfer to Juventus in a transfer worth an initial €100 million (£88 million). He won several trophies in Italy, including two Serie A titles and a Coppa Italia, and broke several records for Juventus. He returned to United in 2021; despite a collectively disappointing season, Ronaldo's individual performances earned him being included in the PFA Team of the Year at 37 years old. His contract was terminated in 2022 due to a fall out with the newly appointed manager, and in 2023 he signed for Al-Nassr, a move that has since been widely credited for revolutionising football in Saudi Arabia.\\nRonaldo made his international debut for Portugal in 2003 at the age of 18 and has earned more than 200 caps, making him history's most-capped male player. Ronaldo has played in eleven major tournaments and scored in ten; he scored his first international goal at Euro 2004, where he helped Portugal reach the final and subsequently made the team of the tournament. In the 2006 FIFA World Cup, his first World Cup, he was a focal part to Portugal ultimately finishing in fourth place. He assumed captaincy of the national team in July 2008 ahead of Euro 2008; four years later, at Euro 2012, he was named to the team of the tournament. In 2015, Ronaldo was named the best Portuguese player of all time by the Portuguese Football Federation. The following year, he led Portugal to their first major tournament title at Euro 2016, being named in the team of the tournament for the third time and receiving the Silver Boot as the second-highest goalscorer of the tournament. This achievement saw him receive his fourth Ballon d'Or. In 2018, Ronaldo had his most prolific World Cup campaign and was voted in the Fan Dream Team. He led his country to victory in the inaugural UEFA Nations League in 2019, receiving the top scorer award in the finals, and also received the Golden Boot as top scorer of Euro 2020. In the 2022 World Cup, he became the first player to score at five World Cups.\\n\\nOne of the world's most marketable and famous athletes, Ronaldo was ranked the world's highest-paid athlete by Forbes in 2016, 2017, 2023, and 2024 and the world's most famous athlete by ESPN from 2016 to 2019. He is the first footballer and the third sportsman to earn US$1 billion in his career. Time included him on their list of the 100 most influential people in the world in 2014. Ronaldo is the most popular sportsperson on social media: he counts over 1 billion total followers across Facebook, Twitter, YouTube and Instagram, making him the first person to achieve that feat. Ronaldo was named in the UEFA Ultimate Team of the Year in 2015, the All-time UEFA Euro XI in 2016, and the Ballon d'Or Dream Team in 2020. In recognition of his record-breaking goalscoring success, he received special awards for Outstanding Career Achievement by FIFA in 2021 and Champions League All-Time Top Scorer by UEFA in 2024.\\n\\n\", name='wikipedia_search', tool_call_id='34a4867d-c5df-4b90-9145-cf23cd3745d5')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Cristiano Ronaldo dos Santos Aveiro is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al-Nassr and the Portugal national team. He is widely regarded as one of the greatest players of all time.\n"
     ]
    }
   ],
   "source": [
    "# We can also stream the individual responses from all nodes and edges in the LangGraph agent. \n",
    "# Streaming messages allows users to receive responses in real-time. \n",
    "# To do so, we can call the stream() function instead of the invoke() method\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "messages = [HumanMessage(content=\"Who is Christiano Ronaldo\")]\n",
    "print_stream(graph.stream({\"messages\": messages}, stream_mode= \"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Latest Research Papers on 'Attention Is All You Need':\n",
      "\n",
      "🔹 Paper #1\n",
      "   🗓️ Published: 2021-07-16\n",
      "   📜 Title: All the attention you need: Global-local, spatial-channel attention for image retrieval\n",
      "   👥 Authors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\n",
      "   📝 Summary: We address representation learning for large-scale instance-level image\n",
      "retrieval. Apart from backbone, training pipelines and loss functions, popular\n",
      "approaches have focused on different spatial pooling and attention mechanisms,\n",
      "which are at the core of learning a powerful global image representation. There\n",
      "are different forms of attention according to the interaction of elements of\n",
      "the feature tensor (local and global) and the dimensions where it is applied\n",
      "(spatial and channel). Unfortunately, each study addresses only one or two\n",
      "forms of attention and applies it to different problems like classification,\n",
      "detection or retrieval.\n",
      "  We present global-local attention module (GLAM), which is attached at the end\n",
      "of a backbone network and incorporates all four forms of attention: local and\n",
      "global, spatial and channel. We obtain a new feature tensor and, by spatial\n",
      "pooling, we learn a powerful embedding for image retrieval. Focusing on global\n",
      "descriptors, we provide empirical evidence of the interaction of all forms of\n",
      "attention and improve the state of the art on standard benchmarks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Paper #2\n",
      "   🗓️ Published: 2023-06-02\n",
      "   📜 Title: RITA: Group Attention is All You Need for Timeseries Analytics\n",
      "   👥 Authors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li\n",
      "   📝 Summary: Timeseries analytics is of great importance in many real-world applications.\n",
      "Recently, the Transformer model, popular in natural language processing, has\n",
      "been leveraged to learn high quality feature embeddings from timeseries, core\n",
      "to the performance of various timeseries analytics tasks. However, the\n",
      "quadratic time and space complexities limit Transformers' scalability,\n",
      "especially for long timeseries. To address these issues, we develop a\n",
      "timeseries analytics tool, RITA, which uses a novel attention mechanism, named\n",
      "group attention, to address this scalability issue. Group attention dynamically\n",
      "clusters the objects based on their similarity into a small number of groups\n",
      "and approximately computes the attention at the coarse group granularity. It\n",
      "thus significantly reduces the time and space complexity, yet provides a\n",
      "theoretical guarantee on the quality of the computed attention. The dynamic\n",
      "scheduler of RITA continuously adapts the number of groups and the batch size\n",
      "in the training process, ensuring group attention always uses the fewest groups\n",
      "needed to meet the approximation quality requirement. Extensive experiments on\n",
      "various timeseries datasets and analytics tasks demonstrate that RITA\n",
      "outperforms the state-of-the-art in accuracy and is significantly faster --\n",
      "with speedups of up to 63X.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def format_paper_results(result):\n",
    "    # Extract the ToolMessage containing arXiv results\n",
    "    tool_message = next(m for m in result['messages'] if isinstance(m, ToolMessage))\n",
    "    papers = tool_message.content.split('\\n\\nPublished: ')[1:] \n",
    "    \n",
    "    print(\"📚 Latest Research Papers on 'Attention Is All You Need':\\n\")\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        # Extract components\n",
    "        parts = paper.split('\\n')\n",
    "        published = parts[0]\n",
    "        title = parts[1].replace('Title: ', '')\n",
    "        authors = parts[2].replace('Authors: ', '')\n",
    "        summary = '\\n'.join(parts[3:]).replace('Summary: ', '')\n",
    "        \n",
    "        print(f\"🔹 Paper #{i}\")\n",
    "        print(f\"   🗓️ Published: {published}\")\n",
    "        print(f\"   📜 Title: {title}\")\n",
    "        print(f\"   👥 Authors: {authors}\")\n",
    "        print(f\"   📝 Summary: {summary}\\n\")\n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "format_paper_results(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
