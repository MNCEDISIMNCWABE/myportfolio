{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import http.client\n",
    "import json\n",
    "import ssl\n",
    "import certifi\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Establish the HTTPS connection\n",
    "conn = http.client.HTTPSConnection(\"linkedin-data-api.p.rapidapi.com\", context=ssl.create_default_context(cafile=certifi.where()))\n",
    "\n",
    "# Set the headers\n",
    "headers = {\n",
    "    'x-rapidapi-key': \"fac8018a9dmshb2ea5c999eb0475p188109jsnf410f35e4ed9\",\n",
    "    'x-rapidapi-host': \"linkedin-data-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Calculate the date 7 days ago\n",
    "seven_days_ago = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Format the date in YYYY-MM-DD for the query\n",
    "seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d')\n",
    "\n",
    "# Example query to search for Data Scientist jobs listed in the last 7 days\n",
    "query = f\"/search-jobs?title=Data+Scientist\"\n",
    "\n",
    "# Make the request to search jobs\n",
    "conn.request(\"GET\", query, headers=headers)\n",
    "\n",
    "# Get the response and read the data\n",
    "res = conn.getresponse()\n",
    "search_data = res.read()\n",
    "\n",
    "# Decode the JSON response from the search\n",
    "search_json_data = json.loads(search_data.decode(\"utf-8\"))\n",
    "\n",
    "# Extract job details\n",
    "jobs_list = search_json_data.get('data', [])\n",
    "\n",
    "# Initialize an empty DataFrame to store all job details\n",
    "all_jobs_df = pd.DataFrame()\n",
    "\n",
    "# Process each job in the list\n",
    "for job_data in jobs_list:\n",
    "    # Get the title, workplace, and listed date\n",
    "    title = job_data.get('title', '')\n",
    "    work_place = job_data.get('workPlace', '')\n",
    "    listed_at_date_str = job_data.get('listedAtDate', '')\n",
    "\n",
    "    # Convert listedAtDate to datetime\n",
    "    if listed_at_date_str:\n",
    "        listed_at_date = datetime.strptime(listed_at_date_str.split(\" +\")[0], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Check conditions: title is \"Data Scientist\", workplace is \"Remote\", and listed within the last 7 days\n",
    "        if title.lower() == 'data scientist' and work_place.lower() == 'remote' and listed_at_date >= seven_days_ago:\n",
    "            # Normalize to DataFrame and append\n",
    "            df = pd.json_normalize(job_data)\n",
    "            all_jobs_df = pd.concat([all_jobs_df, df], ignore_index=True)\n",
    "\n",
    "job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'You have exceeded the MONTHLY quota for Credits on your current plan, BASIC. Upgrade your plan at https://rapidapi.com/rockapis-rockapis-default/api/linkedin-data-api'}\n"
     ]
    }
   ],
   "source": [
    "print(search_json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
