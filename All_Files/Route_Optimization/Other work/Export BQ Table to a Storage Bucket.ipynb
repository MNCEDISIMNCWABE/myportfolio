{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "from google.oauth2.service_account import Credentials\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2770609",
   "metadata": {},
   "source": [
    "### Nando's Qatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5f0ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported data_dump_table to gs://cowabunga-nandos-qatar-live-data/data_dump_table.csv.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the JSON key file\n",
    "# JSON File needs storage.objects.create or storage.objectAdmin access roles\n",
    "# and  bigquery.jobUser/  bigquery.Editor to the project \n",
    "\n",
    "bucket_name = 'cowabunga-nandos-qatar-live-data'\n",
    "project_id = 'cowabunga-nandos-qatar-live'\n",
    "dataset_id = 'cowabunga_trip_dataset'\n",
    "table_name = 'data_dump_table'\n",
    "\n",
    "key_file_path = 'C:/Users/leemn/Documents/Loop Service Account/cb-prod-297913-623cea238b9a.json'\n",
    "\n",
    "# Load the credentials from the key file\n",
    "creds = Credentials.from_service_account_file(key_file_path)\n",
    "\n",
    "# Initialize the BigQuery and Cloud Storage clients\n",
    "bq_client = bigquery.Client(project=project_id, credentials=creds)\n",
    "storage_client = storage.Client(project=project_id, credentials=creds)\n",
    "\n",
    "# Get the table reference\n",
    "table_ref = bq_client.dataset(dataset_id).table(table_name)\n",
    "\n",
    "\n",
    "# Set the destination URI\n",
    "destination_uri = f'gs://{bucket_name}/{table_name}.csv'\n",
    "\n",
    "# Export the table to Cloud Storage\n",
    "extract_job = bq_client.extract_table(table_ref, destination_uri)\n",
    "extract_job.result()\n",
    "\n",
    "print(f'Exported {table_name} to {destination_uri}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d471aed",
   "metadata": {},
   "source": [
    "### Nando's SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ede5e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported cowabunga_startrun_table to gs://cowabunga-nandos-live-data/cowabunga_startrun_table.csv.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the JSON key file\n",
    "# JSON File needs storage.objects.create or storage.objectAdmin access roles\n",
    "# and  bigquery.jobUser/  bigquery.Editor to the project \n",
    "\n",
    "bucket_name = 'cowabunga-nandos-live-data'\n",
    "project_id = 'cowabunga-nandos-live'\n",
    "dataset_id = 'cowabunga_startrun_dataset'\n",
    "table_name = 'cowabunga_startrun_table'\n",
    "\n",
    "key_file_path = 'C:/Users/leemn/Documents/Loop Service Account/cb-prod-297913-623cea238b9a.json'\n",
    "\n",
    "# Load the credentials from the key file\n",
    "creds = Credentials.from_service_account_file(key_file_path)\n",
    "\n",
    "# Initialize the BigQuery and Cloud Storage clients\n",
    "bq_client = bigquery.Client(project=project_id, credentials=creds)\n",
    "storage_client = storage.Client(project=project_id, credentials=creds)\n",
    "\n",
    "# Get the table reference\n",
    "table_ref = bq_client.dataset(dataset_id).table(table_name)\n",
    "\n",
    "\n",
    "# Set the destination URI\n",
    "destination_uri = f'gs://{bucket_name}/{table_name}.csv'\n",
    "\n",
    "# Export the table to Cloud Storage\n",
    "extract_job = bq_client.extract_table(table_ref, destination_uri)\n",
    "extract_job.result()\n",
    "\n",
    "print(f'Exported {table_name} to {destination_uri}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31e7b6",
   "metadata": {},
   "source": [
    "### When the table is too large to be exported to a single file - splits the file to diffrent csv/avro files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83a8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported cowabunga_trip_history to gs://cowabunga-nandos-qatar-live-data/cowabunga_trip_history_*.avro.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the JSON key file\n",
    "# JSON File needs storage.objects.create or storage.objectAdmin access roles\n",
    "# and  bigquery.jobUser/  bigquery.Editor to the project \n",
    "\n",
    "bucket_name = 'cowabunga-nandos-qatar-live-data'\n",
    "project_id = 'cowabunga-nandos-qatar-live'\n",
    "dataset_id = 'cowabunga_trip_dataset'\n",
    "table_name = 'cowabunga_trip_history'\n",
    "\n",
    "\n",
    "key_file_path = 'C:/Users/leemn/Documents/Loop Service Account/cb-prod-297913-623cea238b9a.json'\n",
    "\n",
    "# Load the credentials from the key file\n",
    "creds = Credentials.from_service_account_file(key_file_path)\n",
    "\n",
    "# Initialize the BigQuery and Cloud Storage clients\n",
    "bq_client = bigquery.Client(project=project_id, credentials=creds)\n",
    "storage_client = storage.Client(project=project_id, credentials=creds)\n",
    "\n",
    "# Get the table reference\n",
    "table_ref = bq_client.dataset(dataset_id).table(table_name)\n",
    "\n",
    "\n",
    "# Set the destination URI\n",
    "destination_uri = f'gs://{bucket_name}/{table_name}_*.avro'\n",
    "\n",
    "# Export the table to Cloud Storage\n",
    "extract_job = bq_client.extract_table(table_ref, destination_uri)\n",
    "extract_job.result()\n",
    "\n",
    "print(f'Exported {table_name} to {destination_uri}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabdc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
