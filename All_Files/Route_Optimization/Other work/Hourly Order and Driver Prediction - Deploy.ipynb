{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "671b8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Send message to slack    \n",
    "slack_credentials = 'https://hooks.slack.com/services/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'\n",
    "title = (f\":rotating_light: Orders and Drivers Predictions Run:\")\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "start_time = datetime.now()\n",
    " \n",
    "def post_to_slack(message,slack_credentials):\n",
    "    data = { \"icon_emoji\": \":white_check_mark:\",\n",
    "             \"attachments\": [{\"color\": \"#9733EE\",\"fields\": [{\"title\": title,\"value\": message,\"short\": \"false\"}]}]}\n",
    "    url = slack_credentials\n",
    "    requests.post(url, json=data, headers={'Content-Type': 'application/json'}, verify=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import pandas_gbq\n",
    "        from prophet import Prophet\n",
    "        import statsmodels.api as sm\n",
    "        from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "        from google.oauth2.service_account import Credentials\n",
    "        from oauth2client.service_account import ServiceAccountCredentials\n",
    "        from tqdm import tqdm\n",
    "        import time\n",
    "        import pygsheets\n",
    "        import datetime as dt\n",
    "        from datetime import datetime\n",
    "        import time\n",
    "        # Multi-processing\n",
    "        from multiprocessing import Pool, cpu_count\n",
    "        # Disable INFO logging\n",
    "        import logging\n",
    "        logger = logging.getLogger('cmdstanpy')\n",
    "        logger.addHandler(logging.NullHandler())\n",
    "        logger.propagate = False\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "        credentials = Credentials.from_service_account_file('C:/Users/leemn/OneDrive/Documents/Service Account/cb-prod-297913-d207de781afd.json')\n",
    "        \n",
    "        #>>>>>>>>>>>>>>>>>>> Pull Training Data for Nando's SA >>>>>>>>>>>>>>>>\n",
    "        query_drivers = '''\n",
    "                      SELECT * FROM `cb-prod-297913.driver_predictor.training_data` \n",
    "                      WHERE client_name IN (\"Nando's SA\")\n",
    "                      '''\n",
    "        df_drivers = pd.read_gbq(query_drivers, project_id='cb-prod-297913', \n",
    "                                 dialect='standard', \n",
    "                                 #progress_bar_type='tqdm_notebook',\n",
    "                                 credentials=credentials)\n",
    "\n",
    "\n",
    "        # Orders & Drivers data\n",
    "        data_orders = df_drivers[['ds','branch_name_received','number_of_orders']]\n",
    "        data_orders.columns = ['ds','branch_name_received', 'y']\n",
    "        data_drivers = df_drivers[['ds','branch_name_received','number_of_drivers']]\n",
    "        data_drivers.columns = ['ds','branch_name_received', 'y']\n",
    "\n",
    "\n",
    "        ##>>>>>>>>>>>>>>>> STAGE 1: Hourly Order Prediction\n",
    "        df_grouped_orders = data_orders.groupby('branch_name_received').filter(lambda x: len(x) >= 2)\n",
    "        final_forecast_orders = pd.DataFrame(columns=['branch_name_received','ds','yhat'])\n",
    "        grouped_orders = df_grouped_orders.groupby('branch_name_received')\n",
    "        for branch in grouped_orders.groups:\n",
    "            group_orders = grouped_orders.get_group(branch)\n",
    "            m_orders = Prophet(interval_width=0.95)\n",
    "            m_orders.fit(group_orders)\n",
    "            future_orders = m_orders.make_future_dataframe(periods=168, freq='H')\n",
    "            forecast_orders = m_orders.predict(future_orders)\n",
    "            forecast_orders['branch_name_received'] = branch\n",
    "            final_forecast_orders = pd.concat([final_forecast_orders, forecast_orders], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        ##>>>>>>>>>>>>>>>>> STAGE 2: Hourly Driver Prediction\n",
    "        df_grouped_drivers = data_drivers.groupby('branch_name_received').filter(lambda x: len(x) >= 2)\n",
    "        final_forecast_drivers = pd.DataFrame(columns=['branch_name_received','ds','yhat'])\n",
    "        grouped_drivers = df_grouped_drivers.groupby('branch_name_received')\n",
    "        for branch in grouped_drivers.groups:\n",
    "            group_drivers = grouped_drivers.get_group(branch)\n",
    "            m_drivers = Prophet(interval_width=0.95)\n",
    "            m_drivers.fit(group_drivers)\n",
    "            future_drivers = m_drivers.make_future_dataframe(periods=168, freq='H')\n",
    "            forecast_drivers = m_drivers.predict(future_drivers)\n",
    "            forecast_drivers['branch_name_received'] = branch\n",
    "            final_forecast_drivers = pd.concat([final_forecast_drivers, forecast_drivers], ignore_index=True)\n",
    "\n",
    "        ## Combined Predictions\n",
    "        final_preds = pd.merge(final_forecast_orders[['ds','branch_name_received','yhat']].rename(columns={'ds':'Hour','yhat':'predicted_orders'}) \n",
    "                       ,final_forecast_drivers[['ds','branch_name_received','yhat']].rename(columns={'ds':'Hour','yhat':'predicted_drivers'})\n",
    "                       ,on=['Hour','branch_name_received'])\n",
    "\n",
    "        final_preds['Hour'] = final_preds['Hour'].astype('datetime64[ns]')\n",
    "        final_preds['predicted_orders'] = final_preds['predicted_orders'].astype('float64')\n",
    "        final_preds['predicted_drivers'] = final_preds['predicted_drivers'].astype('float64')\n",
    "\n",
    "        \n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Push predictions to BigQuery >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        final_preds.to_gbq(destination_table = 'cb-prod-297913.driver_predictor.cb-predicted_drivers',\n",
    "               project_id = 'cb-prod-297913',\n",
    "               credentials = credentials,\n",
    "               chunksize = 50000,\n",
    "               #progress_bar = True,\n",
    "               if_exists = 'replace')\n",
    "        \n",
    "        # post message to slack\n",
    "        post_to_slack(f\"\"\"\n",
    "                      :white_check_mark: Successful!\n",
    "                       client: {df_drivers['client_name'].unique()}\n",
    "                       n_branches: {final_preds['branch_name_received'].nunique()}\n",
    "                       training_prediction_time: {round((datetime.now() - start_time).total_seconds(),3)} sec\n",
    "                      \"\"\"\n",
    "                      ,slack_credentials)\n",
    "        \n",
    "    except:\n",
    "        error_msg = f\":warning: Oops, Error in the script!!!\"\n",
    "        post_to_slack(error_msg,slack_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea741a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
