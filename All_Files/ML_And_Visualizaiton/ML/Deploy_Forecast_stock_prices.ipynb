{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60de3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  14 of 14 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:04:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:04:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:04:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:04:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:04:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:04:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:04:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:05:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:05:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "37338 out of 37338 rows loaded.?it/s]\n",
      "37338 out of 37338 rows loaded.\n",
      "37338 out of 37338 rows loaded.\n",
      "37338 out of 37338 rows loaded.\n",
      "37338 out of 37338 rows loaded.\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Send message to slack    \n",
    "slack_credentials = 'https://hooks.slack.com/services/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'\n",
    "message = 'Predictions ran successfully!'\n",
    "\n",
    " \n",
    "def post_to_slack(message,slack_credentials):\n",
    "    data = {'text':message}\n",
    "    url = slack_credentials\n",
    "    requests.post(url,json=data, verify=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import yfinance as yf\n",
    "        from prophet import Prophet\n",
    "        import statsmodels.api as sm\n",
    "        from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "        import pygsheets\n",
    "        from google.oauth2.service_account import Credentials\n",
    "        from oauth2client.service_account import ServiceAccountCredentials\n",
    "        from tqdm import tqdm\n",
    "        from time import time\n",
    "        import json\n",
    "        import requests\n",
    "\n",
    "        # Visualization\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # Multi-processing\n",
    "        from multiprocessing import Pool, cpu_count\n",
    "\n",
    "        # Spark\n",
    "        from pyspark.sql.types import *\n",
    "        from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "        import sqlalchemy as db\n",
    "        from sqlalchemy import create_engine\n",
    "        import mysql.connector\n",
    "        import psycopg2\n",
    "        import pandas_gbq\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        # GBQ logging\n",
    "        import logging\n",
    "        logger = logging.getLogger('pandas_gbq')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "        credentials = Credentials.from_service_account_file('C:/Users/leemn/Documents/Service Account/bright-arc-328707-173b23869758.json')\n",
    "\n",
    "        #start and end date for training\n",
    "        start_date = '2014-01-02'\n",
    "        end_date = pd.to_datetime(\"today\").strftime(\"%Y-%m-%d\")  \n",
    "\n",
    "        # Download data\n",
    "        ticker_list =  ['CLS.JO', 'GLN.JO', 'PPH.JO','WHL.JO','APN.JO','RBP.JO','PIK.JO',\n",
    "                          'HIL.JO','SOL.JO','EXX.JO','MCG.JO','AIL.JO','TGA.JO','SSW.JO']\n",
    "        data = yf.download(ticker_list, start=start_date, end=end_date)[['Close']]\n",
    "        data.columns = data.columns.droplevel()\n",
    "        data = data/100\n",
    "\n",
    "        # Release Date from the index\n",
    "        data = data.reset_index()\n",
    "\n",
    "        # Change data from the wide format to the long format\n",
    "        df = pd.melt(data, id_vars='Date', value_vars= ['CLS.JO', 'GLN.JO', 'PPH.JO','WHL.JO','APN.JO','RBP.JO','PIK.JO',\n",
    "                                                        'HIL.JO','SOL.JO','EXX.JO','MCG.JO','AIL.JO','TGA.JO','SSW.JO'])\n",
    "        df.columns = ['ds', 'ticker', 'y']\n",
    "\n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Train Model>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        # Group the data by ticker\n",
    "        groups_by_ticker = df.groupby('ticker')\n",
    "        # Check the groups in the dataframe\n",
    "        groups_by_ticker.groups.keys()\n",
    "\n",
    "        def train_and_forecast(group):\n",
    "            m = Prophet(interval_width = 0.95)\n",
    "            m.fit(group)\n",
    "            future = m.make_future_dataframe(periods = 465)\n",
    "            forecast = m.predict(future)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "            forecast['ticker'] = group['ticker'].iloc[0]\n",
    "            return forecast[['ds', 'ticker', 'yhat', 'yhat_upper', 'yhat_lower']]\n",
    "\n",
    "\n",
    "        for_loop_forecast = pd.DataFrame()\n",
    "        # Loop through each ticker\n",
    "        for ticker in ticker_list:\n",
    "            group = groups_by_ticker.get_group(ticker)  \n",
    "            forecast = train_and_forecast(group)\n",
    "            for_loop_forecast = pd.concat((for_loop_forecast, forecast))\n",
    "            \n",
    "            \n",
    "            \n",
    "        # give the tickers clear names\n",
    "        for_loop_forecast['ticker_name'] = np.where(for_loop_forecast['ticker']=='CLS.JO','Clicks',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='GLN.JO','Glencore',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='PPH.JO','Pepkorh',         \n",
    "                                  (np.where(for_loop_forecast['ticker']=='WHL.JO','Woolies',        \n",
    "                                  (np.where(for_loop_forecast['ticker']=='APN.JO','Aspen',  \n",
    "                                  (np.where(for_loop_forecast['ticker']=='RBP.JO','Royal-Bafokeng',  \n",
    "                                  (np.where(for_loop_forecast['ticker']=='PIK.JO','PnP',          \n",
    "                                  (np.where(for_loop_forecast['ticker']=='HIL.JO','HomeChoice',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='SOL.JO','Sasol',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='EXX.JO','Exxaro',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='MCG.JO','MultiChoice',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='AIL.JO','African-Rainbow',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='TGA.JO','Thungela',\n",
    "                                  (np.where(for_loop_forecast['ticker']=='SSW.JO','Sibanye-Stillwater',\n",
    "                                  for_loop_forecast.ticker)))))))))))))))))))))))))))\n",
    "    \n",
    "    \n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Push Predictions to Google sheet file >>>>>>>>>>>>>>>>>>>>>\n",
    "        file = 'C:/Users/leemn/Documents/Service Account/bright-arc-328707-173b23869758.json'\n",
    "        id = '1wu6wT8GwPitzhY8Yov3FspFBTd2dC6znKKNcbwP70UQ'\n",
    "        s_n = 'share_price_forecast'\n",
    "\n",
    "\n",
    "        def write_to_gsheet(service_file_path, spreadsheet_id, sheet_name, data_df):\n",
    "            gc = pygsheets.authorize(service_file=service_file_path)\n",
    "            sh = gc.open_by_key(spreadsheet_id)\n",
    "            try:\n",
    "                sh.add_worksheet(sheet_name)\n",
    "            except:\n",
    "                pass\n",
    "            wks_write = sh.worksheet_by_title(sheet_name)\n",
    "            wks_write.clear('A1',None,'*')\n",
    "            wks_write.set_dataframe(data_df, (1,1), encoding='utf-8', fit=True)\n",
    "            wks_write.frozen_rows = 1\n",
    "\n",
    "        write_to_gsheet(file, id, s_n, for_loop_forecast)\n",
    "\n",
    "\n",
    "\n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Push predictions to BigQuery >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        for_loop_forecast.to_gbq(destination_table='bright-arc-328707.test.stock_price_predictions',\n",
    "                                 project_id='bright-arc-328707',\n",
    "                                 credentials=credentials,\n",
    "                                 chunksize=100000,\n",
    "                                 progress_bar=True,\n",
    "                                 if_exists='replace')\n",
    "        \n",
    "        # post message to slack\n",
    "        post_to_slack(message,slack_credentials)\n",
    "    except:\n",
    "        msg = 'Error in the script!'\n",
    "        post_to_slack(msg,slack_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45499bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
