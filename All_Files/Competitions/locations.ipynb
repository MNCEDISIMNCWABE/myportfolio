{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analysis and data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "import datetime as dt\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path_to_csv_file):\n",
    "    '''\n",
    "    Reads csv files from specified paths\n",
    "\n",
    "    Parameters:\n",
    "            path to csv file locations\n",
    "    Returns:\n",
    "            dataframes of imported csv files\n",
    "    '''\n",
    "    # Read CSV files\n",
    "    df = pd.read_csv(path_to_csv_file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# call the function to import train data - update with relevant paths\n",
    "train_df = read_data('/Users/mncedisimncwabe/Downloads/Train.csv')\n",
    "test_df = read_data('/Users/mncedisimncwabe/Downloads/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EllicottCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001136212718088192                                                NaN   \n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "\n",
       "                 location  \n",
       "0            EllicottCity  \n",
       "1                Maryland  \n",
       "2                Maryland  \n",
       "3      Baltimore Maryland  \n",
       "4  Ellicott City Maryland  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle null values\n",
    "train_df['text'].fillna('', inplace=True)\n",
    "train_df.dropna(subset=['location'], inplace=True)\n",
    "test_df['text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td></td>\n",
       "      <td>EllicottCity</td>\n",
       "      <td>What is happening to the infrastructure in New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>SOLDER MISSING IN FLOOD PRAY FOR EDDISON HERMO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>RT TIME Police searching for missing person af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "      <td>Flash Flood Tears Through Maryland Town For Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>Ellicott City FLOODING Pictures Maryland Gover...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001136212718088192                                                      \n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "\n",
       "                 location                                       cleaned_text  \n",
       "0            EllicottCity  What is happening to the infrastructure in New...  \n",
       "1                Maryland  SOLDER MISSING IN FLOOD PRAY FOR EDDISON HERMO...  \n",
       "2                Maryland  RT TIME Police searching for missing person af...  \n",
       "3      Baltimore Maryland  Flash Flood Tears Through Maryland Town For Se...  \n",
       "4  Ellicott City Maryland  Ellicott City FLOODING Pictures Maryland Gover...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean the text data\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # Remove special characters\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove leading/trailing/extra spaces\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "# Apply cleaning function to the test data\n",
    "train_df['cleaned_text'] = test_df['text'].astype(str).apply(clean_text)\n",
    "test_df['cleaned_text'] = test_df['text'].astype(str).apply(clean_text)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30422,)\n",
      "(13038,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['cleaned_text'], train_df['location'], test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model for token classification\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = BertForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline for NER\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract location mentions using the BERT model\n",
    "def extract_locations_batch(texts):\n",
    "    ner_results = nlp(texts)\n",
    "    locations = []\n",
    "    for result in ner_results:\n",
    "        locs = [res['word'] for res in result if 'LOC' in res['entity_group']]\n",
    "        locations.append(' '.join(locs) if locs else \"None\")\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 408/408 [31:13<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54566    None\n",
      "66329    None\n",
      "56439    None\n",
      "61298    None\n",
      "69287    None\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the model on X_test in batches\n",
    "batch_size = 32  # Adjust batch size according to your system's capacity\n",
    "X_test_pred = []\n",
    "\n",
    "for i in tqdm(range(0, len(X_test), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_texts = [str(text) for text in X_test[i:i + batch_size]]  # Ensure each text is a string\n",
    "    X_test_pred.extend(extract_locations_batch(batch_texts))\n",
    "\n",
    "# Convert predictions to a pandas Series\n",
    "X_test_pred = pd.Series(X_test_pred, index=X_test.index)\n",
    "print(X_test_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER on X_test: 1.5473999079613439\n"
     ]
    }
   ],
   "source": [
    "# Function to compute Word Error Rate (WER)\n",
    "def wer(reference, hypothesis):\n",
    "    r = reference.split()\n",
    "    h = hypothesis.split()\n",
    "    d = [[0 for x in range(len(h)+1)] for y in range(len(r)+1)]\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[i][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][j] = i\n",
    "            else:\n",
    "                substitution_cost = 0 if r[i-1] == h[j-1] else 1\n",
    "                d[i][j] = min(d[i-1][j] + 1,      # Deletion\n",
    "                              d[i][j-1] + 1,      # Insertion\n",
    "                              d[i-1][j-1] + substitution_cost)  # Substitution\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "# Calculate WER for each row in X_test\n",
    "wer_scores = [wer(ref, hyp) for ref, hyp in zip(y_test, X_test_pred)]\n",
    "\n",
    "# Output the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f'Average WER on X_test: {average_wer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Data: 100%|██████████| 92/92 [07:51<00:00,  5.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# Apply the trained model on test_df in batches\n",
    "test_df_pred = []\n",
    "for i in tqdm(range(0, len(test_df), batch_size), desc=\"Processing Test Data\"):\n",
    "    batch_texts = [str(text) for text in test_df['cleaned_text'][i:i + batch_size]]  # Ensure each text is a string\n",
    "    test_df_pred.extend(extract_locations_batch(batch_texts))\n",
    "\n",
    "# Assign predictions to test_df\n",
    "test_df['locations_pred'] = test_df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('/Users/mncedisimncwabe/Downloads/loc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model if not already installed\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30422,)\n",
      "(13038,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['cleaned_text'], train_df['location'], test_size=0.3, random_state=42)\n",
    "print(X_train.shape),\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract location mentions\n",
    "def extract_locations(text):\n",
    "    text = str(text)  # Ensure the input is a string\n",
    "    doc = nlp(text)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ == 'GPE' or ent.label_ == 'LOC']\n",
    "    return ' '.join(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54566    \n",
       "66329    \n",
       "56439    \n",
       "61298    \n",
       "69287    \n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the model on X_test\n",
    "X_test_pred = X_test.apply(extract_locations)\n",
    "X_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER on X_test: 1.5272281024697039\n"
     ]
    }
   ],
   "source": [
    "# Function to compute Word Error Rate (WER)\n",
    "def wer(reference, hypothesis):\n",
    "    r = reference.split()\n",
    "    h = hypothesis.split()\n",
    "    d = [[0 for x in range(len(h)+1)] for y in range(len(r)+1)]\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[i][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][j] = i\n",
    "            else:\n",
    "                substitution_cost = 0 if r[i-1] == h[j-1] else 1\n",
    "                d[i][j] = min(d[i-1][j] + 1,      # Deletion\n",
    "                              d[i][j-1] + 1,      # Insertion\n",
    "                              d[i-1][j-1] + substitution_cost)  # Substitution\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "# Calculate WER for each row in X_test\n",
    "wer_scores = [wer(ref, hyp) for ref, hyp in zip(y_test, X_test_pred)]\n",
    "\n",
    "# Output the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f'Average WER on X_test: {average_wer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>locations_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001154804658286592</td>\n",
       "      <td>What is happening to the infrastructure in New...</td>\n",
       "      <td>What is happening to the infrastructure in New...</td>\n",
       "      <td>New England New Orleans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001155505459486720</td>\n",
       "      <td>SOLDER MISSING IN FLOOD.. PRAY FOR EDDISON HER...</td>\n",
       "      <td>SOLDER MISSING IN FLOOD PRAY FOR EDDISON HERMO...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001155756371136512</td>\n",
       "      <td>RT @TIME: Police searching for missing person ...</td>\n",
       "      <td>RT TIME Police searching for missing person af...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001159445194399744</td>\n",
       "      <td>Flash Flood Tears Through Maryland Town For Se...</td>\n",
       "      <td>Flash Flood Tears Through Maryland Town For Se...</td>\n",
       "      <td>Ellicott City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001164907587538944</td>\n",
       "      <td>Ellicott City #FLOODING Pictures: Maryland Gov...</td>\n",
       "      <td>Ellicott City FLOODING Pictures Maryland Gover...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001154804658286592  What is happening to the infrastructure in New...   \n",
       "1  ID_1001155505459486720  SOLDER MISSING IN FLOOD.. PRAY FOR EDDISON HER...   \n",
       "2  ID_1001155756371136512  RT @TIME: Police searching for missing person ...   \n",
       "3  ID_1001159445194399744  Flash Flood Tears Through Maryland Town For Se...   \n",
       "4  ID_1001164907587538944  Ellicott City #FLOODING Pictures: Maryland Gov...   \n",
       "\n",
       "                                        cleaned_text           locations_pred  \n",
       "0  What is happening to the infrastructure in New...  New England New Orleans  \n",
       "1  SOLDER MISSING IN FLOOD PRAY FOR EDDISON HERMO...                           \n",
       "2  RT TIME Police searching for missing person af...   Ellicott City Maryland  \n",
       "3  Flash Flood Tears Through Maryland Town For Se...            Ellicott City  \n",
       "4  Ellicott City FLOODING Pictures Maryland Gover...                           "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the trained model on test_df\n",
    "test_df['locations_pred'] = test_df['cleaned_text'].apply(extract_locations)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('/Users/mncedisimncwabe/Downloads/locations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
