{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain candidates based on search critetia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET https://api.lusha.com/v2/person?firstName=:firstName&lastName=:lastName&companyName=:companyName -H api_key:API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employee IDs returned: 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "# Set up logging and ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def search_employees_one_row_per_employee_dedup(\n",
    "    query,\n",
    "    country_filter=None,\n",
    "    location_filter=None,\n",
    "    company_filter=None,\n",
    "    university_filter=None,\n",
    "    industry_filter=None,\n",
    "    skills_filter=None,\n",
    "    certifications_filter=None,\n",
    "    languages_filter=None,\n",
    "    max_to_fetch=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Search employees by:\n",
    "      - 'query' (e.g. 'CEO', 'CEO OR CFO', etc.)\n",
    "      - Optional filters:\n",
    "            country_filter (e.g. 'South Africa'),\n",
    "            location_filter (e.g. 'Johannesburg, Gauteng, South Africa'),\n",
    "            company_filter (search in company names),\n",
    "            university_filter (search in university names),\n",
    "            industry_filter (search in the top-level industry field),\n",
    "            skills_filter (search in skills),\n",
    "            certifications_filter (search in certifications),\n",
    "            languages_filter (search in languages),\n",
    "            projects_filter (provided for consistency but not used in the search query).\n",
    "\n",
    "    In the final DataFrame (one row per employee):\n",
    "      - Keeps: ID, Name, Headline/Title, Location, Country, URL, Canonical_URL, Industry,\n",
    "               Experience Count, Summary.\n",
    "      - Includes: deduplicated Experiences (with duration), Educations, Skills, Certifications,\n",
    "                  Languages, and Projects.\n",
    "    \"\"\"\n",
    "    # Build the list of must clauses.\n",
    "    must_clauses = []\n",
    "\n",
    "    # Base clause: search in experience title.\n",
    "    must_clauses.append({\n",
    "        \"nested\": {\n",
    "            \"path\": \"member_experience_collection\",\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                    \"query\": query,\n",
    "                    \"default_field\": \"member_experience_collection.title\",\n",
    "                    \"default_operator\": \"and\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Additional filter: Company Name (in experience collection)\n",
    "    if company_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_experience_collection\",\n",
    "                \"query\": {\n",
    "                    \"match_phrase\": {\n",
    "                        \"member_experience_collection.company_name\": company_filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: University Name (in education collection)\n",
    "    if university_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_education_collection\",\n",
    "                \"query\": {\n",
    "                    \"match_phrase\": {\n",
    "                        \"member_education_collection.title\": university_filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Industry (top-level field)\n",
    "    if industry_filter:\n",
    "        must_clauses.append({\n",
    "            \"match_phrase\": {\n",
    "                \"industry\": industry_filter\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Skills (in skills collection)\n",
    "    if skills_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_skills_collection\",\n",
    "                \"query\": {\n",
    "                    \"match_phrase\": {\n",
    "                        \"member_skills_collection.member_skill_list.skill\": skills_filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Certifications (in certifications collection)\n",
    "    if certifications_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_certifications_collection\",\n",
    "                \"query\": {\n",
    "                    \"match_phrase\": {\n",
    "                        \"member_certifications_collection.name\": certifications_filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Languages (in languages collection)\n",
    "    if languages_filter:\n",
    "        # Convert the search term to lower case so that \"English\" matches stored \"english\"\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_languages_collection\",\n",
    "                \"query\": {\n",
    "                    \"match_phrase\": {\n",
    "                        \"member_languages_collection.member_language_list.language\": languages_filter.lower()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Exclude patterns in titles\n",
    "    exclude_patterns = [\"PA to\", \"Assistant to\", \"Personal Assistant\", \"EA to\",\"Executive Assistant to\"]\n",
    "    must_not_clauses = [\n",
    "        {\n",
    "            \"nested\": {\n",
    "                \"path\": \"member_experience_collection\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": f\"member_experience_collection.title:({pattern})\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for pattern in exclude_patterns\n",
    "    ]\n",
    "\n",
    "    # Build the complete payload with country and location filters added.\n",
    "    payload = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": must_clauses,\n",
    "                \"must_not\": must_not_clauses\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if country_filter:\n",
    "        payload[\"query\"][\"bool\"][\"must\"].append({\n",
    "            \"term\": {\n",
    "                \"country\": country_filter\n",
    "            }\n",
    "        })\n",
    "\n",
    "    if location_filter:\n",
    "        payload[\"query\"][\"bool\"][\"must\"].append({\n",
    "            \"match_phrase\": {\n",
    "                \"location\": location_filter\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Uncomment for debugging:\n",
    "    # print(json.dumps(payload, indent=2))\n",
    "\n",
    "    # Send the search request.\n",
    "    search_url = \"https://api.coresignal.com/cdapi/v1/professional_network/employee/search/es_dsl\"\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer eyJhbGciOiJFZERTQSIsImtpZCI6IjYzOGY5Y2YyLTUyM2UtOGJmMC0zZmFlLTEyY2UwNTUzOTQ1YiJ9.eyJhdWQiOiJzdHVkZW50LnVqLmFjLnphIiwiZXhwIjoxNzczMjc2NTkzLCJpYXQiOjE3NDE3MTk2NDEsImlzcyI6Imh0dHBzOi8vb3BzLmNvcmVzaWduYWwuY29tOjgzMDAvdjEvaWRlbnRpdHkvb2lkYyIsIm5hbWVzcGFjZSI6InJvb3QiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJzdHVkZW50LnVqLmFjLnphIiwic3ViIjoiOTc4OGQ4OTYtMjcwYy01ODY4LTE2NDItOTFhYmQ5NDBhMDg2IiwidXNlcmluZm8iOnsic2NvcGVzIjoiY2RhcGkifX0.GYI_XfOwh_DiuBMu9q_JRL39v4bOgJixOWIxPG0ZujADWVFtQQKO1tNJ71ig-ncoRJJE7R6z0WbG4Bxjs_qkDw'\n",
    "    }\n",
    "\n",
    "    resp = requests.post(search_url, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    employee_ids = resp.json()\n",
    "\n",
    "    if not isinstance(employee_ids, list):\n",
    "        print(\"Unexpected structure in search response.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Collect data for each employee ID.\n",
    "    rows = []\n",
    "    for emp_id in employee_ids[:max_to_fetch]:\n",
    "        collect_url = f\"https://api.coresignal.com/cdapi/v1/professional_network/employee/collect/{emp_id}\"\n",
    "        r = requests.get(collect_url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        employee = r.json()\n",
    "\n",
    "\n",
    "        # Basic fields\n",
    "        id_val = employee.get(\"id\")\n",
    "        name_val = employee.get(\"name\")\n",
    "        headline_val = employee.get(\"title\")\n",
    "        location_val = employee.get(\"location\")\n",
    "        country_val = employee.get(\"country\")\n",
    "        url_val = employee.get(\"url\")\n",
    "        canonical_url = employee.get(\"canonical_url\")\n",
    "        industry_val = employee.get(\"industry\")\n",
    "        experience_count_val = employee.get(\"experience_count\")\n",
    "        summary_val = employee.get(\"summary\")\n",
    "\n",
    "        # ----- EXPERIENCE (deduplicate) -----\n",
    "        raw_exps = employee.get(\"member_experience_collection\", [])\n",
    "        unique_exps = []\n",
    "        seen_exps = set()\n",
    "        for exp in raw_exps:\n",
    "            key = (\n",
    "                exp.get(\"title\", \"N/A\"),\n",
    "                exp.get(\"company_name\", \"N/A\"),\n",
    "                exp.get(\"date_from\", \"N/A\"),\n",
    "                exp.get(\"date_to\", \"N/A\")\n",
    "            )\n",
    "            if key not in seen_exps:\n",
    "                seen_exps.add(key)\n",
    "                unique_exps.append(exp)\n",
    "        experiences_str = \"\\n\".join(\n",
    "            f\"Role: {exp.get('title','N/A')} | Company: {exp.get('company_name','N/A')} | From: {exp.get('date_from','N/A')} | To: {exp.get('date_to','N/A')} | Duration: {exp.get('duration','N/A')}\"\n",
    "            for exp in unique_exps\n",
    "        )\n",
    "\n",
    "        # ----- EDUCATION (deduplicate) -----\n",
    "        raw_edu = employee.get(\"member_education_collection\", [])\n",
    "        unique_edu = []\n",
    "        seen_edu = set()\n",
    "        for edu in raw_edu:\n",
    "            key = (\n",
    "                edu.get(\"title\", \"N/A\"),\n",
    "                edu.get(\"subtitle\", \"N/A\"),\n",
    "                edu.get(\"date_from\", \"N/A\"),\n",
    "                edu.get(\"date_to\", \"N/A\")\n",
    "            )\n",
    "            if key not in seen_edu:\n",
    "                seen_edu.add(key)\n",
    "                unique_edu.append(edu)\n",
    "        educations_str = \"\\n\".join(\n",
    "            f\"Institution: {edu.get('title','N/A')} | Degree: {edu.get('subtitle','N/A')} | From: {edu.get('date_from','N/A')} | To: {edu.get('date_to','N/A')}\"\n",
    "            for edu in unique_edu\n",
    "        )\n",
    "\n",
    "        # ----- SKILLS (deduplicate) -----\n",
    "        raw_skills = employee.get(\"member_skills_collection\", [])\n",
    "        seen_skills = set()\n",
    "        for skill_entry in raw_skills:\n",
    "            skill_name = skill_entry.get(\"member_skill_list\", {}).get(\"skill\", \"N/A\")\n",
    "            seen_skills.add(skill_name)\n",
    "        skills_str = \", \".join(seen_skills) if seen_skills else \"\"\n",
    "\n",
    "        # ----- CERTIFICATIONS (deduplicate) -----\n",
    "        raw_certifications = employee.get(\"member_certifications_collection\", [])\n",
    "        seen_certs = set()\n",
    "        for cert in raw_certifications:\n",
    "            cert_name = cert.get(\"name\", \"N/A\")\n",
    "            seen_certs.add(cert_name)\n",
    "        certifications_str = \", \".join(seen_certs) if seen_certs else \"\"\n",
    "\n",
    "        # ----- LANGUAGES (deduplicate) -----\n",
    "        raw_languages = employee.get(\"member_languages_collection\", [])\n",
    "        seen_langs = set()\n",
    "        for lang in raw_languages:\n",
    "            language_name = lang.get(\"member_language_list\", {}).get(\"language\", \"N/A\")\n",
    "            seen_langs.add(language_name)\n",
    "        languages_str = \", \".join(seen_langs) if seen_langs else \"\"\n",
    "\n",
    "        # ----- PROJECTS (deduplicate) -----\n",
    "        raw_projects = employee.get(\"member_projects_collection\", [])\n",
    "        seen_projects = set()\n",
    "        for proj in raw_projects:\n",
    "            proj_name = proj.get(\"name\", \"N/A\")\n",
    "            seen_projects.add(proj_name)\n",
    "        projects_str = \", \".join([str(x) for x in seen_projects if x is not None]) if seen_projects else \"\"\n",
    "\n",
    "        # Build the final row dictionary.\n",
    "        row = {\n",
    "            \"ID\": id_val,\n",
    "            \"Name\": name_val,\n",
    "            \"Headline/Title\": headline_val,\n",
    "            \"Location\": location_val,\n",
    "            \"Country\": country_val,\n",
    "            \"URL\": url_val,\n",
    "            \"Canonical_URL\": canonical_url,\n",
    "            \"Industry\": industry_val,\n",
    "            \"Experience Count\": experience_count_val,\n",
    "            \"Summary\": summary_val,\n",
    "            \"Experiences\": experiences_str,\n",
    "            \"Educations\": educations_str,\n",
    "            \"Skills\": skills_str,\n",
    "            \"Certifications\": certifications_str,\n",
    "            \"Languages\": languages_str,\n",
    "            \"Projects\": projects_str\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    # After the search API call\n",
    "    print(f\"Number of employee IDs returned: {len(employee_ids)}\")\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = '(\"Head of Legal\")'\n",
    "    country = \"South Africa\"\n",
    "    location = \"Johannesburg\"\n",
    "    # company = \"PWC\"\n",
    "    # university = \"University of Cape Town\"\n",
    "    # industry = \"Accounting\"\n",
    "    # skills = \"managerial finance\"\n",
    "    # certifications = \"Assessor\"\n",
    "    # languages = \"English\"\n",
    "\n",
    "    df_employees = search_employees_one_row_per_employee_dedup(\n",
    "        query=user_query,\n",
    "        #country_filter=country,\n",
    "        #location_filter=location,\n",
    "        # company_filter=company,\n",
    "        # university_filter=university,\n",
    "        # industry_filter=industry,\n",
    "        # skills_filter=skills,\n",
    "        # certifications_filter=certifications,\n",
    "        # languages_filter=languages,\n",
    "        max_to_fetch=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import requests\n",
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "from typing import List, Optional\n",
    "import io\n",
    "import hashlib\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set up logging and ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def search_employees_one_row_per_employee_dedup(\n",
    "    query,\n",
    "    country_filter=None,\n",
    "    location_filter=None,\n",
    "    company_filter=None,\n",
    "    university_filter=None,\n",
    "    industry_filter=None,\n",
    "    skills_filter=None,\n",
    "    certifications_filter=None,\n",
    "    languages_filter=None,\n",
    "    max_to_fetch=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Search employees by:\n",
    "      - 'query' (e.g. 'CEO', 'CEO OR CFO', etc.)\n",
    "      - Optional filters:\n",
    "            country_filter (e.g. 'South Africa'),\n",
    "            location_filter (e.g. 'Johannesburg, Gauteng, South Africa'),\n",
    "            company_filter (search in company names),\n",
    "            university_filter (search in university names),\n",
    "            industry_filter (search in the top-level industry field),\n",
    "            skills_filter (search in skills),\n",
    "            certifications_filter (search in certifications),\n",
    "            languages_filter (search in languages),\n",
    "            projects_filter (provided for consistency but not used in the search query).\n",
    "\n",
    "    In the final DataFrame (one row per employee):\n",
    "      - Keeps: ID, Name, Headline/Title, Location, Country, URL, Canonical_URL, Industry,\n",
    "               Experience Count, Summary.\n",
    "      - Includes: deduplicated Experiences (with duration), Educations, Skills, Certifications,\n",
    "                  Languages, and Projects.\n",
    "    \"\"\"\n",
    "    # Build the list of must clauses.\n",
    "    must_clauses = []\n",
    "\n",
    "    # Base clause: search in experience title\n",
    "    must_clauses.append({\n",
    "        \"nested\": {\n",
    "            \"path\": \"experience\",\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                    \"query\": query,\n",
    "                    \"default_field\": \"experience.position_title\",\n",
    "                    \"default_operator\": \"and\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Additional filter: Company Name (in experience)\n",
    "    if company_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"experience\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": company_filter,\n",
    "                        \"default_field\": \"experience.company_name\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: University Name (in education)\n",
    "    if university_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"education\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": university_filter,\n",
    "                        \"default_field\": \"education.institution_name\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Industry (in experience)\n",
    "    if industry_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"experience\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": industry_filter,\n",
    "                        \"default_field\": \"experience.company_industry\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Skills (in inferred_skills)\n",
    "    if skills_filter:\n",
    "        must_clauses.append({\n",
    "            \"query_string\": {\n",
    "                \"query\": skills_filter,\n",
    "                \"default_field\": \"inferred_skills\",\n",
    "                \"default_operator\": \"or\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Certifications\n",
    "    if certifications_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"certifications\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": certifications_filter,\n",
    "                        \"default_field\": \"certifications.title\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Additional filter: Languages\n",
    "    if languages_filter:\n",
    "        must_clauses.append({\n",
    "            \"nested\": {\n",
    "                \"path\": \"languages\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": languages_filter.lower(),\n",
    "                        \"default_field\": \"languages.language\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Exclude patterns in titles\n",
    "    exclude_patterns = [\"PA to\", \"Assistant to\", \"Personal Assistant\", \"EA to\", \"Executive Assistant to\",\"Head of the Office of the CFO\",\"Head of the Office of the CEO\"]\n",
    "    must_not_clauses = [\n",
    "        {\n",
    "            \"nested\": {\n",
    "                \"path\": \"experience\",\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": f\"experience.position_title:({pattern})\",\n",
    "                        \"default_operator\": \"or\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for pattern in exclude_patterns\n",
    "    ]\n",
    "\n",
    "    # Build the complete payload with country and location filters added.\n",
    "    payload = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": must_clauses,\n",
    "                \"must_not\": must_not_clauses\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if country_filter:\n",
    "        payload[\"query\"][\"bool\"][\"must\"].append({\n",
    "            \"query_string\": {\n",
    "                \"query\": country_filter,\n",
    "                \"default_field\": \"location_country\",\n",
    "                \"default_operator\": \"and\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    if location_filter:\n",
    "        payload[\"query\"][\"bool\"][\"must\"].append({\n",
    "            \"query_string\": {\n",
    "                \"query\": location_filter,\n",
    "                \"default_field\": \"location_full\",\n",
    "                \"default_operator\": \"and\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Uncomment for debugging:\n",
    "    # print(json.dumps(payload, indent=2))\n",
    "\n",
    "    # Send the search request.\n",
    "    search_url = \"https://api.coresignal.com/cdapi/v1/multi_source/employee/search/es_dsl\"\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer eyJhbGciOiJFZERTQSIsImtpZCI6IjMzNjEyYzA1LWQ2MDYtYzllYy0zNGVjLWRiYmJiNGI0ZjgyMCJ9.eyJhdWQiOiJtdWx0aWNob2ljZS5jby56YSIsImV4cCI6MTc3MzQwNjg1OCwiaWF0IjoxNzQxODQ5OTA2LCJpc3MiOiJodHRwczovL29wcy5jb3Jlc2lnbmFsLmNvbTo4MzAwL3YxL2lkZW50aXR5L29pZGMiLCJuYW1lc3BhY2UiOiJyb290IiwicHJlZmVycmVkX3VzZXJuYW1lIjoibXVsdGljaG9pY2UuY28uemEiLCJzdWIiOiI5Nzg4ZDg5Ni0yNzBjLTU4NjgtMTY0Mi05MWFiZDk0MGEwODYiLCJ1c2VyaW5mbyI6eyJzY29wZXMiOiJjZGFwaSJ9fQ.GFaoIY_j8e3TKs9-iQ0H6O7NVz87T3Z7ZWIWPRHo17IrWqmehNvvJ8sD3BMaDVatHs9rr9C3hpUykkwS53HrAw' \n",
    "    }\n",
    "\n",
    "    resp = requests.post(search_url, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    employee_ids = resp.json()\n",
    "\n",
    "    if not isinstance(employee_ids, list):\n",
    "        print(\"Unexpected structure in search response.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Collect data for each employee ID.\n",
    "    rows = []\n",
    "    for emp_id in employee_ids[:max_to_fetch]:\n",
    "        \n",
    "        collect_url = f\"https://api.coresignal.com/cdapi/v1/multi_source/employee/collect/{emp_id}\"\n",
    "        r = requests.get(collect_url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        employee = r.json()\n",
    "\n",
    "        # Basic fields\n",
    "        id_val = employee.get(\"id\")\n",
    "        name_val = employee.get(\"full_name\")\n",
    "        headline_val = employee.get(\"headline\")\n",
    "        location_val = employee.get(\"location_full\")\n",
    "        country_val = employee.get(\"location_country\")\n",
    "        url_val = employee.get(\"linkedin_url\")\n",
    "        canonical_url = employee.get(\"linkedin_url\")  # Using LinkedIn URL as canonical\n",
    "        industry_val = None  # Not available in top level, will need to be extracted from experience\n",
    "        experience_count_val = len(employee.get(\"experience\", []))\n",
    "        summary_val = employee.get(\"summary\")\n",
    "        \n",
    "        # Get email information\n",
    "        primary_email = employee.get(\"primary_professional_email\")\n",
    "        \n",
    "        # Get all email addresses from collection\n",
    "        email_collection = employee.get(\"professional_emails_collection\", [])\n",
    "        all_emails = [email_info.get(\"professional_email\") for email_info in email_collection if email_info.get(\"professional_email\")]\n",
    "        all_emails_str = \", \".join(all_emails) if all_emails else \"\"\n",
    "\n",
    "        # ----- EXPERIENCE (deduplicate) -----\n",
    "        raw_exps = employee.get(\"experience\", [])\n",
    "        unique_exps = []\n",
    "        seen_exps = set()\n",
    "        company_industries = set()  # Set to collect unique industries\n",
    "        for exp in raw_exps:\n",
    "            key = (\n",
    "                exp.get(\"position_title\", \"N/A\"),\n",
    "                exp.get(\"company_name\", \"N/A\"),\n",
    "                exp.get(\"date_from\", \"N/A\"),\n",
    "                exp.get(\"date_to\", \"N/A\")\n",
    "            )\n",
    "            if key not in seen_exps:\n",
    "                seen_exps.add(key)\n",
    "                unique_exps.append(exp)\n",
    "                # Add industry to the set if it exists\n",
    "                if exp.get(\"company_industry\"):\n",
    "                    company_industries.add(exp.get(\"company_industry\"))\n",
    "\n",
    "        experiences_str = \"\\n\".join(\n",
    "            f\"Role: {exp.get('position_title','N/A')} | Company: {exp.get('company_name','N/A')} | From: {exp.get('date_from','N/A')} | To: {exp.get('date_to','N/A')} | Duration: {exp.get('duration_months','N/A')} months\"\n",
    "            for exp in unique_exps\n",
    "        )\n",
    "\n",
    "        # Create a formatted string of industries\n",
    "        company_industry_str = \" | \".join(sorted(company_industries)) if company_industries else \"N/A\"\n",
    "\n",
    "        # ----- EDUCATION (deduplicate) -----\n",
    "        raw_edu = employee.get(\"education\", [])\n",
    "        unique_edu = []\n",
    "        seen_edu = set()\n",
    "        for edu in raw_edu:\n",
    "            key = (\n",
    "                edu.get(\"institution_name\", \"N/A\"),\n",
    "                edu.get(\"degree\", \"N/A\"),\n",
    "                str(edu.get(\"date_from_year\", \"N/A\")),\n",
    "                str(edu.get(\"date_to_year\", \"N/A\"))\n",
    "            )\n",
    "            if key not in seen_edu:\n",
    "                seen_edu.add(key)\n",
    "                unique_edu.append(edu)\n",
    "        educations_str = \"\\n\".join(\n",
    "            f\"Institution: {edu.get('institution_name','N/A')} | Degree: {edu.get('degree','N/A')} | From: {edu.get('date_from_year','N/A')} | To: {edu.get('date_to_year','N/A')}\"\n",
    "            for edu in unique_edu\n",
    "        )\n",
    "\n",
    "        # ----- SKILLS (deduplicate) -----\n",
    "        skills = employee.get(\"inferred_skills\", [])\n",
    "        skills_str = \", \".join(skills) if skills else \"\"\n",
    "\n",
    "        # ----- CERTIFICATIONS (deduplicate) -----\n",
    "        raw_certifications = employee.get(\"certifications\", [])\n",
    "        seen_certs = set()\n",
    "        for cert in raw_certifications:\n",
    "            cert_name = cert.get(\"title\", \"N/A\")\n",
    "            seen_certs.add(cert_name)\n",
    "        certifications_str = \", \".join(seen_certs) if seen_certs else \"\"\n",
    "\n",
    "        # ----- LANGUAGES (deduplicate) -----\n",
    "        raw_languages = employee.get(\"languages\", [])\n",
    "        seen_langs = set()\n",
    "        for lang in raw_languages:\n",
    "            language_name = lang.get(\"language\", \"N/A\")\n",
    "            seen_langs.add(language_name)\n",
    "        languages_str = \", \".join(seen_langs) if seen_langs else \"\"\n",
    "\n",
    "        # ----- PROJECTS (deduplicate) -----\n",
    "        raw_projects = employee.get(\"projects\", [])\n",
    "        seen_projects = set()\n",
    "        for proj in raw_projects:\n",
    "            proj_name = proj.get(\"name\", \"N/A\")\n",
    "            seen_projects.add(proj_name)\n",
    "        projects_str = \", \".join([str(x) for x in seen_projects if x is not None]) if seen_projects else \"\"\n",
    "\n",
    "        # ----- AWARDS (deduplicate) -----\n",
    "        raw_awards = employee.get(\"awards\", [])\n",
    "        seen_awards = set()\n",
    "        for award in raw_awards:\n",
    "            award_name = award.get(\"title\", \"N/A\")\n",
    "            seen_awards.add(award_name)\n",
    "        awards_str = \", \".join(seen_awards) if seen_awards else \"\"\n",
    "\n",
    "        # ----- PATENTS (deduplicate) -----\n",
    "        raw_patents = employee.get(\"patents\", [])\n",
    "        seen_patents = set()\n",
    "        for patent in raw_patents:\n",
    "            patent_name = patent.get(\"title\", \"N/A\")\n",
    "            seen_patents.add(patent_name)\n",
    "        patents_str = \", \".join(seen_patents) if seen_patents else \"\"\n",
    "\n",
    "        # ----- PUBLICATIONS (deduplicate) -----\n",
    "        raw_publications = employee.get(\"publications\", [])\n",
    "        seen_publications = set()\n",
    "        for pub in raw_publications:\n",
    "            pub_name = pub.get(\"title\", \"N/A\")\n",
    "            seen_publications.add(pub_name)\n",
    "        publications_str = \", \".join(seen_publications) if seen_publications else \"\"\n",
    "\n",
    "        # ----- SALARY INFORMATION -----\n",
    "        projected_base_salary_median = employee.get(\"projected_base_salary_median\")\n",
    "        projected_base_salary_currency = employee.get(\"projected_base_salary_currency\")\n",
    "        projected_base_salary_period = employee.get(\"projected_base_salary_period\")\n",
    "        \n",
    "        salary_str = \"\"\n",
    "        if projected_base_salary_median:\n",
    "            salary_str = f\"{projected_base_salary_currency}{projected_base_salary_median:,.2f} {projected_base_salary_period}\"\n",
    "\n",
    "        # Build the final row dictionary.\n",
    "        row = {\n",
    "            \"ID\": id_val,\n",
    "            \"Name\": name_val,\n",
    "            \"Headline/Title\": headline_val,\n",
    "            \"Location\": location_val,\n",
    "            \"Country\": country_val,\n",
    "            \"URL\": url_val,\n",
    "            \"Primary Email\": primary_email,\n",
    "            \"All Emails\": all_emails_str,\n",
    "            \"Industry\": company_industry_str, \n",
    "            \"Experience Count\": experience_count_val,\n",
    "            \"Summary\": summary_val,\n",
    "            \"Experiences\": experiences_str,\n",
    "            \"Educations\": educations_str,\n",
    "            \"Skills\": skills_str,\n",
    "            \"Certifications\": certifications_str,\n",
    "            \"Languages\": languages_str,\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    # After the search API call\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"('Head Of Legal')\"\n",
    "\n",
    "    df_employees = search_employees_one_row_per_employee_dedup(\n",
    "        query=user_query,\n",
    "        max_to_fetch=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling - compare candidate profiles with job description to get similarity scores and rank based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.4.0 available.\n",
      "INFO:datasets:TensorFlow version 2.17.0 available.\n",
      "INFO:__main__:Starting candidate ranking process...\n",
      "INFO:__main__:Combining candidate text fields...\n",
      "INFO:__main__:Processed 1 candidate profiles\n",
      "INFO:__main__:Filtering empty candidate texts...\n",
      "INFO:__main__:Removed 0 empty profiles, 1 remaining\n",
      "INFO:__main__:Initializing sentence transformer model: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Preprocessing job description...\n",
      "INFO:__main__:Encoding job description...\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "INFO:__main__:Preprocessing candidate texts...\n",
      "INFO:__main__:Encoding candidate texts in batches of 32...\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s]\n",
      "INFO:__main__:Successfully encoded 1 candidate texts\n",
      "INFO:__main__:Calculating cosine similarities...\n",
      "INFO:__main__:Similarity scores range: 0.688 - 0.688\n",
      "INFO:__main__:Sorting candidates by similarity score...\n",
      "INFO:__main__:Top candidate score: 0.688\n",
      "INFO:__main__:Ranking process completed successfully\n",
      "INFO:__main__:Script execution completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import logging\n",
    "import warnings\n",
    "from typing import List, Optional\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def build_user_text(row, text_columns: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Combine relevant text fields into a single string for semantic comparison.\n",
    "    Handles both string and list-type columns.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row containing user information\n",
    "        text_columns: List of columns to include in combined text\n",
    "        \n",
    "    Returns:\n",
    "        Combined text string\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for col in text_columns:\n",
    "        val = row.get(col)\n",
    "        if pd.notnull(val):\n",
    "            if isinstance(val, list):\n",
    "                parts.append(' '.join(map(str, val)))\n",
    "            else:\n",
    "                parts.append(str(val))\n",
    "    return \" \".join(parts).strip()\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and normalize text input by:\n",
    "    - Removing emojis and special characters\n",
    "    - Removing extra whitespace\n",
    "    - Converting to lowercase\n",
    "    \"\"\"\n",
    "    # Remove emojis using Unicode range patterns\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # CJK symbols\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove special characters and punctuation (keep alphanumeric and whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase and clean whitespace\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.strip().split())\n",
    "    return text\n",
    "\n",
    "def rank_candidates_semantic(\n",
    "    df_employees: pd.DataFrame,\n",
    "    job_description: str,\n",
    "    text_columns: Optional[List[str]] = None,\n",
    "    model_name: str = 'all-MiniLM-L6-v2',\n",
    "    batch_size: int = 32\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rank candidates based on semantic similarity to job description.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting candidate ranking process...\")\n",
    "        \n",
    "        # Create working copy to avoid modifying original dataframe\n",
    "        df = df_employees.copy()\n",
    "        \n",
    "        # Set columns for corpus\n",
    "        if text_columns is None:\n",
    "            text_columns = ['Summary', 'Experiences', 'Educations', \n",
    "                           'Headline/Title', 'Industry', 'Skills'\n",
    "                           'Certifications','Projects']\n",
    "            logger.debug(f\"Using default text columns: {text_columns}\")\n",
    "        else:\n",
    "            logger.debug(f\"Using custom text columns: {text_columns}\")\n",
    "\n",
    "        # 1) Create combined text for each user\n",
    "        logger.info(\"Combining candidate text fields...\")\n",
    "        df['combined_text'] = df.apply(\n",
    "            lambda x: build_user_text(x, text_columns), \n",
    "            axis=1\n",
    "        )\n",
    "        logger.info(f\"Processed {len(df)} candidate profiles\")\n",
    "\n",
    "        # Handle empty texts to avoid encoding issues\n",
    "        logger.info(\"Filtering empty candidate texts...\")\n",
    "        initial_count = len(df)\n",
    "        df['combined_text'] = df['combined_text'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        df = df.dropna(subset=['combined_text']).reset_index(drop=True)\n",
    "        filtered_count = len(df)\n",
    "        logger.info(f\"Removed {initial_count - filtered_count} empty profiles, {filtered_count} remaining\")\n",
    "\n",
    "        if df.empty:\n",
    "            logger.warning(\"No valid candidate texts found after preprocessing\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # 2) Initialize sentence transformer model\n",
    "        logger.info(f\"Initializing sentence transformer model: {model_name}\")\n",
    "        model = SentenceTransformer(model_name)\n",
    "        \n",
    "        # 3) Preprocess and embed job description\n",
    "        logger.info(\"Preprocessing job description...\")\n",
    "        clean_jd = preprocess_text(job_description)\n",
    "        logger.debug(f\"Job description length: {len(clean_jd.split())} words\")\n",
    "        \n",
    "        logger.info(\"Encoding job description...\")\n",
    "        job_embedding = model.encode(clean_jd, convert_to_tensor=True)\n",
    "        logger.debug(f\"Job embedding shape: {job_embedding.shape}\")\n",
    "\n",
    "        # 4) Embed candidate texts in batches\n",
    "        logger.info(\"Preprocessing candidate texts...\")\n",
    "        user_texts = df['combined_text'].apply(preprocess_text).tolist()\n",
    "        logger.debug(f\"First candidate text preview: {user_texts[0][:200]}...\")\n",
    "        \n",
    "        logger.info(f\"Encoding candidate texts in batches of {batch_size}...\")\n",
    "        user_embeddings = model.encode(\n",
    "            user_texts,\n",
    "            convert_to_tensor=True,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        logger.info(f\"Successfully encoded {len(user_texts)} candidate texts\")\n",
    "        logger.debug(f\"Embeddings matrix shape: {user_embeddings.shape}\")\n",
    "\n",
    "        # 5) Calculate cosine similarities\n",
    "        logger.info(\"Calculating cosine similarities...\")\n",
    "        similarities = util.cos_sim(job_embedding, user_embeddings)\n",
    "        df['similarity_score'] = similarities.cpu().numpy().flatten()\n",
    "        \n",
    "        # Calculate score statistics\n",
    "        min_score = df['similarity_score'].min()\n",
    "        max_score = df['similarity_score'].max()\n",
    "        logger.info(f\"Similarity scores range: {min_score:.3f} - {max_score:.3f}\")\n",
    "        logger.debug(f\"Score distribution:\\n{df['similarity_score'].describe()}\")\n",
    "\n",
    "        # 6) Sort and return results\n",
    "        logger.info(\"Sorting candidates by similarity score...\")\n",
    "        df_sorted = df.sort_values(by='similarity_score', ascending=False)\\\n",
    "                      .reset_index(drop=True)\n",
    "        \n",
    "        logger.info(f\"Top candidate score: {df_sorted.iloc[0]['similarity_score']:.3f}\")\n",
    "        logger.info(\"Ranking process completed successfully\")\n",
    "        \n",
    "        return df_sorted\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in ranking candidates: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_description_text = \"\"\"\n",
    "        About the job\n",
    "        A well-established investment management company with nationwide operations are \n",
    "        looking for a highly skilled and experienced Chief Financial Officer (CFO) to join \n",
    "        their dynamic team. This leadership role is based in Stellenbosch, Western Cape.\n",
    "\n",
    "        As CFO, you will lead financial strategy, ensure strong financial management, \n",
    "        and drive sustainable growth, optimising operations and profitability for long-term success. \n",
    "        Additionally, the CFO will oversee all financial operations, including budgeting, \n",
    "        forecasting, reporting, cash flow management, and regulatory compliance.\n",
    "\n",
    "        Key Responsibilities:\n",
    "\n",
    "        Prepare accurate financial reports, including monthly, quarterly, and annual statements.\n",
    "        Provide financial analysis to support strategic planning and decision-making.\n",
    "        Monitor key metrics to ensure financial health and performance.\n",
    "        Develop and manage budgets in alignment with company goals.\n",
    "        Track financial performance, highlight variances, and recommend corrective actions.\n",
    "        Oversee cash flow, receivables, and payables to maintain liquidity.\n",
    "        Ensure compliance with financial regulations, tax laws, and industry standards.\n",
    "        Lead external audits and coordinate with auditors.\n",
    "        Collaborate with leadership on long-term financial strategies.\n",
    "        Conduct financial modelling to support growth, investments, and cost management.\n",
    "        Work cross-functionally with other departments within the organization (intercompany loans etc.)\n",
    "\n",
    "        Qualifications and Experience:\n",
    "\n",
    "        Qualified CA(SA) or CGMA\n",
    "        5 years minimum of experience working in a managerial/leadership role\n",
    "        Proven track record in financial modelling and analysis\n",
    "    \n",
    "    \"\"\" \n",
    "    try:\n",
    "        df_ranked = rank_candidates_semantic(\n",
    "            df_employees=df_employees,\n",
    "            job_description=job_description_text,\n",
    "            model_name='all-MiniLM-L6-v2'\n",
    "        )\n",
    "        logger.info(\"Script execution completed\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in main execution: {e}\")\n",
    "        print(f\"Error processing candidates: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Headline/Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>URL</th>\n",
       "      <th>Canonical_URL</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Experience Count</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Experiences</th>\n",
       "      <th>Educations</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Certifications</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Projects</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24938138</td>\n",
       "      <td>Puseletso Gobinca CA(SA)</td>\n",
       "      <td>CFO at Lonsa Everite</td>\n",
       "      <td>City of Johannesburg, Gauteng, South Africa</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>https://www.linkedin.com/in/puseletso-gobinca-...</td>\n",
       "      <td>https://www.linkedin.com/in/puseletso-gobinca-...</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>Role: Senior Corporate Finance Specialist | Co...</td>\n",
       "      <td>Institution: University of Cape Town | Degree:...</td>\n",
       "      <td>credit analysis, managerial finance, legal con...</td>\n",
       "      <td>Assessor</td>\n",
       "      <td>english</td>\n",
       "      <td>TOPP Programme Implementantion: National Treas...</td>\n",
       "      <td>Role: Senior Corporate Finance Specialist | Co...</td>\n",
       "      <td>0.687969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                      Name        Headline/Title  \\\n",
       "0  24938138  Puseletso Gobinca CA(SA)  CFO at Lonsa Everite   \n",
       "\n",
       "                                      Location       Country  \\\n",
       "0  City of Johannesburg, Gauteng, South Africa  South Africa   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.linkedin.com/in/puseletso-gobinca-...   \n",
       "\n",
       "                                       Canonical_URL    Industry  \\\n",
       "0  https://www.linkedin.com/in/puseletso-gobinca-...  Accounting   \n",
       "\n",
       "   Experience Count Summary  \\\n",
       "0                17    None   \n",
       "\n",
       "                                         Experiences  \\\n",
       "0  Role: Senior Corporate Finance Specialist | Co...   \n",
       "\n",
       "                                          Educations  \\\n",
       "0  Institution: University of Cape Town | Degree:...   \n",
       "\n",
       "                                              Skills Certifications Languages  \\\n",
       "0  credit analysis, managerial finance, legal con...       Assessor   english   \n",
       "\n",
       "                                            Projects  \\\n",
       "0  TOPP Programme Implementantion: National Treas...   \n",
       "\n",
       "                                       combined_text  similarity_score  \n",
       "0  Role: Senior Corporate Finance Specialist | Co...          0.687969  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admin': {'password': '9c8fda2d3b2d5d51d71ceaab96f8a23980250021c2320e033b92351c1100bbfb', 'email': 'admin@example.com', 'created_at': datetime.datetime(2025, 3, 10, 21, 17, 51, 15493), 'role': 'admin'}, 'Lindani': {'password': '709ab09a04fb33a48680f243cafaa781753870f90ff4e395821b2bcaade5c002', 'email': 'leemncwabe29@gmail.com', 'created_at': datetime.datetime(2025, 3, 10, 22, 44, 1, 394674), 'role': 'user', 'reset_token': '98f1d158-4b87-430f-a39a-51c1582c1275', 'reset_token_expiry': datetime.datetime(2025, 3, 16, 17, 5, 25, 850308)}, 'LeeM': {'password': '8d0d43bc7ae6dd3970389ffae089fdc6ba85e300c332f7e4a2bef8b01d52de2b', 'email': '3621029@myuwc.ac.za', 'created_at': datetime.datetime(2025, 3, 16, 16, 49, 53, 358297), 'role': 'user'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'admin': {'password': '9c8fda2d3b2d5d51d71ceaab96f8a23980250021c2320e033b92351c1100bbfb',\n",
       "  'email': 'admin@example.com',\n",
       "  'created_at': datetime.datetime(2025, 3, 10, 21, 17, 51, 15493),\n",
       "  'role': 'admin'},\n",
       " 'Lindani': {'password': '709ab09a04fb33a48680f243cafaa781753870f90ff4e395821b2bcaade5c002',\n",
       "  'email': 'leemncwabe29@gmail.com',\n",
       "  'created_at': datetime.datetime(2025, 3, 10, 22, 44, 1, 394674),\n",
       "  'role': 'user',\n",
       "  'reset_token': '98f1d158-4b87-430f-a39a-51c1582c1275',\n",
       "  'reset_token_expiry': datetime.datetime(2025, 3, 16, 17, 5, 25, 850308)},\n",
       " 'LeeM': {'password': '8d0d43bc7ae6dd3970389ffae089fdc6ba85e300c332f7e4a2bef8b01d52de2b',\n",
       "  'email': '3621029@myuwc.ac.za',\n",
       "  'created_at': datetime.datetime(2025, 3, 16, 16, 49, 53, 358297),\n",
       "  'role': 'user'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View content of a pickle file\n",
    "\n",
    "import pickle\n",
    "def view_pickle_file(file_path):\n",
    "    \"\"\"Opens and displays the contents of a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            print(data) \n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except pickle.UnpicklingError:\n",
    "        print(\"Error: Invalid pickle file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "file_path = 'users.pkl'\n",
    "view_pickle_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
