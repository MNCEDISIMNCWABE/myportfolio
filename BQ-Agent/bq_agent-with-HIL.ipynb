{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing: Give me a list of top 5 users by engagement time\n",
      "==================================================\n",
      "\n",
      "Attempt 1/3\n",
      "\n",
      "Generating SQL for: Give me a list of top 5 users by engagement time\n",
      "Generated SQL (raw): ```sql\n",
      "SELECT \n",
      "    user_id, \n",
      "    SUM(engagement_time_minutes) AS total_engagement_time\n",
      "FROM \n",
      "    `hallowed-span-459710-s1.test_clustering.user-engagement`\n",
      "GROUP BY \n",
      "    user_id\n",
      "ORDER BY \n",
      "    total_engagement_time DESC\n",
      "LIMIT 5\n",
      "```\n",
      "\n",
      "==================================================\n",
      "HUMAN APPROVAL REQUIRED\n",
      "Generated SQL Query:\n",
      "```sql\n",
      "SELECT \n",
      "    user_id, \n",
      "    SUM(engagement_time_minutes) AS total_engagement_time\n",
      "FROM \n",
      "    `hallowed-span-459710-s1.test_clustering.user-engagement`\n",
      "GROUP BY \n",
      "    user_id\n",
      "ORDER BY \n",
      "    total_engagement_time DESC\n",
      "LIMIT 5\n",
      "```\n",
      "\n",
      "Question being answered: Give me a list of top 5 users by engagement time\n",
      "\n",
      "You can type:\n",
      "- 'Y' or 'Yes' to approve\n",
      "- 'N' or 'No' to reject\n",
      "- 'Yes but...' followed by your feedback/suggestions to modify the query\n",
      "Executing query: SELECT \n",
      "    user_id, \n",
      "    SUM(engagement_time_minutes) AS total_engagement_time\n",
      "FROM \n",
      "    `hallowed-span-459710-s1.test_clustering.user-engagement`\n",
      "GROUP BY \n",
      "    user_id\n",
      "ORDER BY \n",
      "    total_engagement_time DESC\n",
      "LIMIT 5\n",
      "\n",
      "Final Result:\n",
      "                                             user_id  total_engagement_time\n",
      "0  372f22bf567cd1293cf068b6e6d91e5c6d4cbe164f77b6...                  648.2\n",
      "1  dac1ebe5ef6f1a24ca6aee33a7e4282b3837f778ef8e5f...                  622.5\n",
      "2  522552616d7a01c0cc870e3101ef1dd6190d4a9a9dc672...                  621.3\n",
      "3  6e00b6466c761d77a0b64e82f98be88cef4af3c9194bb9...                  582.4\n",
      "4  8311b47eac7849c5dd91f6516f89423acdc39680607447...                  475.7\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_community import BigQueryLoader\n",
    "from google.cloud import bigquery\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.graph import Graph, END\n",
    "from typing import TypedDict, Annotated, Union, Optional\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/mncedisimncwabe/Downloads/hallowed-span-459710-s1-c41d79c9b56b.json\"\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "def get_all_schemas(dataset_id):\n",
    "    \"\"\"Fetch schemas for all tables in the dataset\"\"\"\n",
    "    tables = client.list_tables(dataset_id)\n",
    "    schemas = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        try:\n",
    "            table_ref = client.get_table(table)\n",
    "            schemas[table.table_id] = [\n",
    "                {\n",
    "                    \"name\": field.name,\n",
    "                    \"type\": field.field_type,\n",
    "                    \"description\": field.description or \"No description\"\n",
    "                }\n",
    "                for field in table_ref.schema\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching schema for {table.table_id}: {str(e)}\")\n",
    "    \n",
    "    return schemas\n",
    "\n",
    "# Get all schemas\n",
    "schemas = get_all_schemas(\"test_clustering\")\n",
    "\n",
    "# Update these\n",
    "BQ_PROJECT = \"hallowed-span-459710-s1\" \n",
    "BQ_DATASET = \"test_clustering\"   \n",
    "LOCATION =  \"us-central1\"  \n",
    "TARGET_TABLES = {                      \n",
    "    \"user-engagement\": \"User engagement data\",\n",
    "    \"dim_date\": \"Date dimension table\",\n",
    "    \"fact_user_metrics\": \"Aggregated user metrics\"\n",
    "}\n",
    "\n",
    "# Initialize Vertex AI LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    temperature=0, # Controls the randomness/creativity of the AI's output. With higher values, it might sometimes add unnecessary clauses.\n",
    "    max_output_tokens=2048, # Set the maximum length of the generated response in tokens (≈ words/word parts). 1,500-2,000 words\n",
    "    project=BQ_PROJECT,\n",
    "    location=LOCATION\n",
    ")\n",
    "\n",
    "def format_schema_for_prompt(schema_data):\n",
    "    \"\"\"Format schema data for human-readable prompt\"\"\"\n",
    "    formatted = []\n",
    "    for table_name, columns in schema_data.items():\n",
    "        formatted.append(f\"Table {table_name}:\")\n",
    "        for col in columns:\n",
    "            formatted.append(f\"  - {col['name']} ({col['type']}): {col['description']}\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "def get_table_reference(table_name: str) -> str:\n",
    "    \"\"\"Generate properly formatted BigQuery table reference\"\"\"\n",
    "    return f\"`{BQ_PROJECT}.{BQ_DATASET}.{table_name}`\"\n",
    "\n",
    "# agent instructions prompt \n",
    "system_prompt = f\"\"\"You are an advanced BigQuery SQL expert with data modeling intuition. Key capabilities:\n",
    "\n",
    "1. Schema Reasoning:\n",
    "- Automatically detect date fields that should join to dim_date (e.g., first_seen_date → dim_date.date)\n",
    "- Recognize common patterns (user_id for joins, *_date for time dimensions)\n",
    "- Identify fact vs dimension tables based on structure\n",
    "\n",
    "2. Intelligent Defaults:\n",
    "- For time-based questions, default to appropriate date granularity (month/quarter/year)\n",
    "- For user metrics, consider both raw (user-engagement) and aggregated (fact_user_metrics) sources\n",
    "- When counting distinct values, automatically add LIMIT based on expected cardinality\n",
    "\n",
    "3. Self-Correction:\n",
    "- If initial query returns unexpected zeros/null values:\n",
    "  1. Check date formatting\n",
    "  2. Verify join conditions\n",
    "  3. Consider alternative source tables\n",
    "\n",
    "4. Analytical Best Practices:\n",
    "- Prefer COUNT(DISTINCT) over COUNT() for user metrics\n",
    "- Use appropriate date functions (EXTRACT, DATE_TRUNC)\n",
    "- Apply CASE WHEN for conditional logic\n",
    "\n",
    "Available tables:\n",
    "{format_schema_for_prompt(schemas)}\n",
    "\n",
    "Examples of Intelligent Behavior:\n",
    "Q: \"How many unique months per user?\"\n",
    "A: SELECT \n",
    "     u.user_id,\n",
    "     COUNT(DISTINCT FORMAT_DATE('%Y-%m', d.date)) AS unique_months\n",
    "   FROM {get_table_reference('user-engagement')} u\n",
    "   JOIN {get_table_reference('dim_date')} d \n",
    "     ON u.first_seen_date = d.date\n",
    "   GROUP BY u.user_id\n",
    "\n",
    "Q: \"Find users active in Q2 but not Q3\"\n",
    "A: WITH q2_users AS (\n",
    "     SELECT DISTINCT user_id \n",
    "     FROM {get_table_reference('user-engagement')} u\n",
    "     JOIN {get_table_reference('dim_date')} d \n",
    "       ON u.first_seen_date = d.date\n",
    "     WHERE d.quarter = 'Q2'\n",
    "   )\n",
    "   SELECT q2.user_id\n",
    "   FROM q2_users q2\n",
    "   WHERE NOT EXISTS (\n",
    "     SELECT 1 \n",
    "     FROM {get_table_reference('user-engagement')} u2\n",
    "     JOIN {get_table_reference('dim_date')} d2 \n",
    "       ON u2.first_seen_date = d2.date\n",
    "     WHERE d2.quarter = 'Q3'\n",
    "     AND u2.user_id = q2.user_id\n",
    "   )\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    sql_query: Optional[str]\n",
    "    query_result: Union[pd.DataFrame, str, None]\n",
    "    validation_errors: list[str]\n",
    "    attempts: int\n",
    "    needs_correction: bool\n",
    "    human_approved: Optional[bool]\n",
    "    human_feedback: Optional[str]\n",
    "    needs_modification: Optional[bool]\n",
    "\n",
    "# Helper function to clean SQL query\n",
    "def clean_sql_query(query: str) -> str:\n",
    "    \"\"\"Clean and normalize SQL query by removing backticks, etc.\"\"\"\n",
    "    if query is None:\n",
    "        return \"\"\n",
    "    if query.startswith(\"```\") and query.endswith(\"```\"):\n",
    "        query = query.strip(\"`\")\n",
    "        if query.lower().startswith(\"sql\"):\n",
    "            query = query[3:].strip()\n",
    "    return query.strip()\n",
    "\n",
    "# Add new helper function for human interaction\n",
    "def get_human_approval(state: AgentState) -> AgentState:\n",
    "    \"\"\"Get human approval for generated SQL with ability to provide feedback\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HUMAN APPROVAL REQUIRED\")\n",
    "    print(\"Generated SQL Query:\")\n",
    "    print(state[\"sql_query\"])\n",
    "    \n",
    "    question = state.get(\"question\", \"Unknown question\")\n",
    "    print(\"\\nQuestion being answered:\", question)\n",
    "    \n",
    "    # Allow for human nuanced feedback\n",
    "    print(\"\\nYou can type:\")\n",
    "    print(\"- 'Y' or 'Yes' to approve\")\n",
    "    print(\"- 'N' or 'No' to reject\")\n",
    "    print(\"- 'Yes but...' followed by your feedback/suggestions to modify the query\")\n",
    "    \n",
    "    feedback = input(\"Your response: \").strip()\n",
    "    \n",
    "    # Process feedback\n",
    "    feedback_lower = feedback.lower()\n",
    "    if feedback_lower.startswith('y') or feedback_lower.startswith('yes'):\n",
    "        is_approved = True\n",
    "        # Check if there's feedback beyond just approval\n",
    "        if 'but' in feedback_lower:\n",
    "            # Extract the modification suggestion\n",
    "            suggestion = feedback[feedback.lower().find('but') + 3:].strip()\n",
    "            return {\n",
    "                **state,\n",
    "                \"human_approved\": True,\n",
    "                \"human_feedback\": suggestion,\n",
    "                \"needs_modification\": True\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"human_approved\": True, \"needs_modification\": False}\n",
    "    else:\n",
    "        # Rejection with potential feedback\n",
    "        suggestion = feedback[2:].strip() if len(feedback) > 2 else \"\"\n",
    "        return {\n",
    "            **state,\n",
    "            \"human_approved\": False,\n",
    "            \"human_feedback\": suggestion if suggestion else \"Query rejected\",\n",
    "            \"needs_modification\": False  # Will go to correction process\n",
    "        }\n",
    "\n",
    "# Initialize the graph\n",
    "workflow = Graph()\n",
    "\n",
    "# Define nodes\n",
    "def generate_sql(state: AgentState) -> AgentState:\n",
    "    # LLM generates SQL query\n",
    "    print(f\"\\nGenerating SQL for: {state['question']}\")\n",
    "    chain = (\n",
    "        {\"question\": lambda x: x[\"question\"]}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    sql_query = chain.invoke(state)\n",
    "    print(f\"Generated SQL (raw): {sql_query}\")\n",
    "    return {\n",
    "        **state,  # Preserve all existing state fields, including question\n",
    "        \"sql_query\": sql_query, \n",
    "        \"attempts\": state.get(\"attempts\", 0) + 1,\n",
    "        \"query_result\": None, \n",
    "        \"validation_errors\": [] \n",
    "    }\n",
    "\n",
    "def validate_sql(state: AgentState) -> AgentState:\n",
    "    query = clean_sql_query(state[\"sql_query\"])\n",
    "    errors = []\n",
    "    \n",
    "    table_ref_pattern = re.compile(\n",
    "        r\"(`\" + re.escape(BQ_PROJECT) + r\"\\.\" + re.escape(BQ_DATASET) + r\"\\.[a-zA-Z0-9_-]+`|`[a-zA-Z0-9_-]+`)\", \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Validation checks\n",
    "    if not query.lower().startswith((\"select\", \"with\")):\n",
    "        errors.append(\"Must start with SELECT/WITH\")\n",
    "    \n",
    "    if not table_ref_pattern.search(query):\n",
    "        errors.append(f\"Missing valid table reference (expected format: `{BQ_PROJECT}.{BQ_DATASET}.table_name` or `table_name`)\")\n",
    "    \n",
    "    if \"join\" in query.lower() and not re.search(r\"\\bjoin\\b(.|\\n)+?\\bon\\b\", query, re.IGNORECASE):\n",
    "        errors.append(\"JOIN missing ON clause\")\n",
    "    \n",
    "    return {\n",
    "        **state,  \n",
    "        \"validation_errors\": errors, \n",
    "        \"sql_query\": state[\"sql_query\"],\n",
    "        \"query_result\": None  \n",
    "    }\n",
    "\n",
    "def execute_query(state: AgentState) -> AgentState:\n",
    "    if state[\"validation_errors\"]:\n",
    "        print(f\"Validation errors: {state['validation_errors']}\")\n",
    "        return {\n",
    "            **state,  \n",
    "            \"query_result\": f\"Validation errors: {', '.join(state['validation_errors'])}\",\n",
    "            \"sql_query\": state[\"sql_query\"],\n",
    "            \"needs_correction\": True\n",
    "        }\n",
    "    \n",
    "    query = clean_sql_query(state[\"sql_query\"])\n",
    "    print(f\"Executing query: {query}\")\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        result = query_job.result().to_dataframe()\n",
    "        return {\n",
    "            **state, \n",
    "            \"query_result\": result,\n",
    "            \"sql_query\": state[\"sql_query\"],\n",
    "            \"needs_correction\": False\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,  \n",
    "            \"query_result\": f\"Execution Error: {str(e)}\",\n",
    "            \"sql_query\": state[\"sql_query\"],\n",
    "            \"needs_correction\": True\n",
    "        }\n",
    "\n",
    "def analyze_results(state: AgentState) -> AgentState:\n",
    "    result_update = {\n",
    "        **state, \n",
    "        \"sql_query\": state[\"sql_query\"],\n",
    "        \"query_result\": state[\"query_result\"]\n",
    "    }\n",
    "    \n",
    "    if isinstance(state[\"query_result\"], str):\n",
    "        print(f\"Problem detected: {state['query_result']}\")\n",
    "        result_update[\"needs_correction\"] = True\n",
    "        return result_update\n",
    "    \n",
    "    if isinstance(state[\"query_result\"], pd.DataFrame):\n",
    "        if state[\"query_result\"].empty:\n",
    "            result_update[\"needs_correction\"] = True\n",
    "            result_update[\"query_result\"] = \"Query returned empty results\"\n",
    "        elif (state[\"query_result\"].iloc[:, 1:] == 0).all().all():\n",
    "            result_update[\"needs_correction\"] = True\n",
    "            result_update[\"query_result\"] = \"Query returned all zeros\"\n",
    "        else:\n",
    "            result_update[\"needs_correction\"] = False\n",
    "    \n",
    "    return result_update\n",
    "\n",
    "def correct_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"Enhanced correction with human feedback context\"\"\"\n",
    "    error_context = state.get(\"query_result\", \"Unknown error\")\n",
    "    \n",
    "    # Special case for human disapproval\n",
    "    if state.get(\"human_approved\") is False:\n",
    "        error_context = \"Human reviewer rejected the generated SQL query\"\n",
    "    \n",
    "    original_query = state.get(\"sql_query\", \"No query generated yet\")\n",
    "    print(f\"\\nAttempting to correct query. Error: {error_context}\")\n",
    "    \n",
    "    question = state.get(\"question\", \"Unknown question\") \n",
    "    \n",
    "    correction_prompt = f\"\"\"Correct this SQL query based on the feedback:\n",
    "    \n",
    "    Error Context: {error_context}\n",
    "    Original Query: {original_query}\n",
    "    \n",
    "    User Question: {question}\n",
    "    \n",
    "    Provide ONLY the corrected SQL query:\"\"\"\n",
    "    \n",
    "    corrected = llm.invoke(correction_prompt)\n",
    "    return {\n",
    "        **state,  \n",
    "        \"sql_query\": corrected.content.strip(),\n",
    "        \"attempts\": state.get(\"attempts\", 0),\n",
    "        \"query_result\": None,\n",
    "        \"validation_errors\": [],\n",
    "        \"human_approved\": None  # Reset approval state\n",
    "    }\n",
    "\n",
    "# Add a new node for handling human modification suggestions\n",
    "def modify_query_based_on_feedback(state: AgentState) -> AgentState:\n",
    "    \"\"\"Modify query based on human feedback\"\"\"\n",
    "    original_query = state[\"sql_query\"]\n",
    "    feedback = state.get(\"human_feedback\", \"\")\n",
    "    \n",
    "    print(f\"\\nModifying query based on feedback: {feedback}\")\n",
    "    \n",
    "    # Construct prompt for the LLM to modify the query\n",
    "    modification_prompt = f\"\"\"\n",
    "    I have a SQL query that needs to be modified based on human feedback.\n",
    "    \n",
    "    Original SQL query:\n",
    "    {original_query}\n",
    "    \n",
    "    Human feedback: {feedback}\n",
    "    \n",
    "    Please modify the query according to this feedback. Return ONLY the modified SQL query.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the LLM to modify the query\n",
    "    modified_query = llm.invoke(modification_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"sql_query\": modified_query.content.strip(),\n",
    "        \"needs_modification\": False,  # Reset flag after modification\n",
    "        \"human_approved\": True  # Consider it approved after modification\n",
    "    }\n",
    "\n",
    "# Add nodes to workflow\n",
    "workflow.add_node(\"generate\", generate_sql)\n",
    "workflow.add_node(\"validate\", validate_sql)\n",
    "workflow.add_node(\"execute\", execute_query)\n",
    "workflow.add_node(\"analyze\", analyze_results)\n",
    "workflow.add_node(\"correct\", correct_query)\n",
    "workflow.add_node(\"human_approval\", get_human_approval)\n",
    "workflow.add_node(\"modify\", modify_query_based_on_feedback)\n",
    "\n",
    "# Set up workflow edges\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.add_edge(\"generate\", \"validate\")\n",
    "workflow.add_edge(\"validate\", \"human_approval\") \n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_approval\",\n",
    "    lambda x: \"modify\" if x.get(\"human_approved\") and x.get(\"needs_modification\", False) else \n",
    "              \"execute\" if x.get(\"human_approved\") else \"correct\",\n",
    "    {\"modify\": \"modify\", \"execute\": \"execute\", \"correct\": \"correct\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"modify\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"analyze\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze\",\n",
    "    lambda x: \"correct\" if x.get(\"needs_correction\", False) and x.get(\"attempts\", 0) < 3 else END,\n",
    "    {\"correct\": \"correct\", END: END}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"correct\", \"validate\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "def bigquery_agent(question: str, max_attempts: int = 3) -> Union[pd.DataFrame, str]:\n",
    "    state = {\n",
    "        \"question\": question,\n",
    "        \"sql_query\": None,\n",
    "        \"query_result\": None,\n",
    "        \"validation_errors\": [],\n",
    "        \"attempts\": 0,\n",
    "        \"needs_correction\": False,\n",
    "        \"human_approved\": None,\n",
    "        \"human_feedback\": None,\n",
    "        \"needs_modification\": False\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        print(f\"\\nAttempt {attempt + 1}/{max_attempts}\")\n",
    "        result_state = app.invoke(state, {\"recursion_limit\": 50})\n",
    "        \n",
    "        # Ensure result_state is not None\n",
    "        if result_state is None:\n",
    "            print(\"Warning: Workflow returned None state. Using previous state.\")\n",
    "            break\n",
    "        else:\n",
    "            state = result_state  \n",
    "        \n",
    "        # Handle early exit if human rejects final attempt\n",
    "        if state.get(\"human_approved\") is False and attempt == max_attempts - 1:\n",
    "            return \"Query rejected by human reviewer\"\n",
    "        \n",
    "        if not state.get(\"needs_correction\", False):\n",
    "            result = state.get(\"query_result\")\n",
    "            if isinstance(result, pd.DataFrame):\n",
    "                return result\n",
    "            else:\n",
    "                return f\"Final result: {result}\"\n",
    "    \n",
    "    return state.get(\"query_result\", \"Max attempts reached without success\")\n",
    "\n",
    "# Test questions\n",
    "questions = [\n",
    "    \"Give me a list of top 5 users by engagement time\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*50}\\nProcessing: {question}\\n{'='*50}\")\n",
    "    result = bigquery_agent(question)\n",
    "    \n",
    "    print(\"\\nFinal Result:\")\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        print(result.head())\n",
    "    else:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph\n",
    "\n",
    "LangChain Handles LLM Interactions:\n",
    "\n",
    "- Generates the initial SQL\n",
    "\n",
    "- Powers the correction mechanism\n",
    "\n",
    "- Formats prompts with schema context\n",
    "\n",
    "LangGraph Manages the Process:\n",
    "\n",
    "- Retries failed queries with full context\n",
    "\n",
    "- Maintains state (attempts, errors, last query)\n",
    "\n",
    "- Decides when to terminate\n",
    "\n",
    "\n",
    "Flow:\n",
    "##### 1. User query:\n",
    "- User types a question e.g Monthly active users by country\n",
    "- LLM (Gemini) uses the schema-aware prompt (system_promot) to pick correct tables/columns then generates raw SQL query\n",
    "\n",
    "##### 2. SQL Cleaning:\n",
    "- LLMs often wrap SQL in markdown e.g (```sql SELECT ....) BigQuery would reject markdown-formatted SQL, so this standardizes input for validation\n",
    "- clean_sql_query() removes formatting to SELECT ...\n",
    "\n",
    "##### 3. Validation (Guardrails)\n",
    "- It then checks for critical errors before execution: e.g Valid table references to prevent \"table not found\" errors or any other syntax errors\n",
    "\n",
    "#### 4. Pre-Execution Approval (First Human Checkpoint)\n",
    "- System pauses and shows the generated query to the human to approve or provide feedback\n",
    "- ✅ Human Approve → Proceeds to execution\n",
    "- Human says \"Yes but...\" → Suggest modifications (e.g., \"Yes but order results in descendint order\"). This is then sent to the LLM to make modifications.\n",
    "- ❌ Reject → Triggers auto-correction\n",
    "\n",
    "\n",
    "##### 4. BigQuery Execution\n",
    "- Sends and runs approved cleaned SQL to BigQuery then return an output of that query in pandas format table\n",
    "\n",
    "##### 5. SQL Query Results Analysis\n",
    "- Checks for semantic issues the validator couldn't catch: e.g empty results , all zeros results \n",
    "\n",
    "##### 6. Self-Correction Loop\n",
    "- If any suspicious results or execution failures were found, contextual feedback will be sent back to the LLM to correct\n",
    "e.g what the LLM would receive \"Fix this: Execution Error: Unrecognized column 'last_active_date'. Valid columns: ['user_id', 'signup_date', ...]\n",
    "- LLM Outputs revised SQL query then restarts from validation\n",
    "\n",
    "##### 7. Final Output\n",
    "- Returns pandas DataFrame (ready for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_orchestrator.py\n",
    "from typing import Dict, Any, Optional, List, Union\n",
    "from pydantic import BaseModel\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "\n",
    "GCP_PROJECT = \"hallowed-span-459710-s1\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# Set up credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/mncedisimncwabe/Downloads/hallowed-span-459710-s1-c41d79c9b56b.json\"\n",
    "\n",
    "# Initialize Vertex AI LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=2048,\n",
    "    project=GCP_PROJECT,\n",
    "    location=LOCATION\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Protocol Definitions\n",
    "# --------------------------\n",
    "\n",
    "class ModelCapability(BaseModel):\n",
    "    \"\"\"Describes what an agent can do\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    data_sources: List[str] = []  # What data this agent can access\n",
    "    query_types: List[str] = []   # Types of queries it can handle\n",
    "    input_schema: Dict[str, Any]\n",
    "    output_schema: Dict[str, Any]\n",
    "    parameters: Dict[str, Any] = {}\n",
    "\n",
    "class ModelContext(BaseModel):\n",
    "    \"\"\"Standardized context object for MCP\"\"\"\n",
    "    session_id: str\n",
    "    timestamp: datetime\n",
    "    context_data: Dict[str, Any]\n",
    "    source_agent: Optional[str] = None\n",
    "    target_agents: Optional[List[str]] = None\n",
    "\n",
    "class A2AMessage(BaseModel):\n",
    "    \"\"\"Standardized agent-to-agent message\"\"\"\n",
    "    message_id: str\n",
    "    sender: str\n",
    "    recipients: List[str]\n",
    "    content: Dict[str, Any]\n",
    "    context: Optional[ModelContext] = None\n",
    "    requires_response: bool = False\n",
    "    expiration: Optional[datetime] = None\n",
    "\n",
    "# --------------------------\n",
    "# Wrappers\n",
    "# --------------------------\n",
    "\n",
    "class MCPWrapper:\n",
    "    \"\"\"Wraps existing agents with MCP capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_instance, agent_name: str, agent_description: str, \n",
    "                 data_sources: List[str] = None, query_types: List[str] = None):\n",
    "        self.agent = agent_instance\n",
    "        self.agent_name = agent_name\n",
    "        self.agent_description = agent_description\n",
    "        self.data_sources = data_sources or []\n",
    "        self.query_types = query_types or []\n",
    "        self.capabilities = self._define_capabilities()\n",
    "        \n",
    "    def _define_capabilities(self) -> List[ModelCapability]:\n",
    "        \"\"\"Define what this agent can do with detailed information\"\"\"\n",
    "        return [\n",
    "            ModelCapability(\n",
    "                name=\"sql_generation_and_execution\",\n",
    "                description=f\"Generates and executes SQL queries for {', '.join(self.data_sources)} data\",\n",
    "                data_sources=self.data_sources,\n",
    "                query_types=self.query_types,\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\"type\": \"string\"},\n",
    "                        \"max_attempts\": {\"type\": \"integer\", \"default\": 3}\n",
    "                    },\n",
    "                    \"required\": [\"question\"]\n",
    "                },\n",
    "                output_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"sql_query\": {\"type\": \"string\"},\n",
    "                        \"query_result\": {\"type\": [\"object\", \"string\"]},\n",
    "                        \"status\": {\"type\": \"string\"}\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def execute(self, context: ModelContext) -> ModelContext:\n",
    "        \"\"\"Execute agent with MCP context\"\"\"\n",
    "        question = context.context_data.get(\"question\")\n",
    "        max_attempts = context.context_data.get(\"max_attempts\", 3)\n",
    "        \n",
    "        # Call the original agent\n",
    "        try:\n",
    "            if \"spanner\" in self.agent_name.lower():\n",
    "                result = self.agent.spanner_agent(question, max_attempts)\n",
    "            else:\n",
    "                result = self.agent.bigquery_agent(question, max_attempts)\n",
    "            \n",
    "            # Convert result to dict if it's a DataFrame\n",
    "            if isinstance(result, pd.DataFrame):\n",
    "                result_data = result.to_dict(orient='records')\n",
    "            else:\n",
    "                result_data = str(result)\n",
    "                \n",
    "            status = \"success\"\n",
    "        except Exception as e:\n",
    "            result_data = str(e)\n",
    "            status = \"error\"\n",
    "        \n",
    "        # Package results into MCP format\n",
    "        result_context = ModelContext(\n",
    "            session_id=context.session_id,\n",
    "            timestamp=datetime.now(),\n",
    "            context_data={\n",
    "                \"question\": question,\n",
    "                \"result\": result_data,\n",
    "                \"status\": status\n",
    "            },\n",
    "            source_agent=self.agent_name\n",
    "        )\n",
    "        \n",
    "        return result_context\n",
    "\n",
    "class A2AWrapper:\n",
    "    \"\"\"Enables agent-to-agent communication\"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_wrapper: MCPWrapper):\n",
    "        self.mcp_agent = mcp_wrapper\n",
    "        self.inbox: List[A2AMessage] = []\n",
    "        \n",
    "    def send_message(self, recipients: List[str], content: Dict[str, Any], requires_response: bool = False) -> A2AMessage:\n",
    "        \"\"\"Send a message to other agents\"\"\"\n",
    "        message = A2AMessage(\n",
    "            message_id=str(uuid.uuid4()),\n",
    "            sender=self.mcp_agent.agent_name,\n",
    "            recipients=recipients,\n",
    "            content=content,\n",
    "            requires_response=requires_response,\n",
    "            expiration=datetime.now() + timedelta(hours=1)\n",
    "        )\n",
    "        return message\n",
    "        \n",
    "    def receive_message(self, message: A2AMessage):\n",
    "        \"\"\"Receive a message from another agent\"\"\"\n",
    "        self.inbox.append(message)\n",
    "        \n",
    "    def process_messages(self) -> Optional[A2AMessage]:\n",
    "        \"\"\"Process all received messages\"\"\"\n",
    "        responses = []\n",
    "        \n",
    "        for message in self.inbox[:]: \n",
    "            if message.expiration and message.expiration < datetime.now():\n",
    "                self.inbox.remove(message)\n",
    "                continue\n",
    "                \n",
    "            if message.requires_response:\n",
    "                # Create context from message\n",
    "                context = ModelContext(\n",
    "                    session_id=message.message_id,\n",
    "                    timestamp=datetime.now(),\n",
    "                    context_data=message.content,\n",
    "                    source_agent=message.sender,\n",
    "                    target_agents=[self.mcp_agent.agent_name]\n",
    "                )\n",
    "                \n",
    "                # Execute the agent\n",
    "                response_context = self.mcp_agent.execute(context)\n",
    "                \n",
    "                # Send response\n",
    "                response = A2AMessage(\n",
    "                    message_id=str(uuid.uuid4()),\n",
    "                    sender=self.mcp_agent.agent_name,\n",
    "                    recipients=[message.sender],\n",
    "                    content=response_context.context_data,\n",
    "                    context=response_context\n",
    "                )\n",
    "                \n",
    "                responses.append(response)\n",
    "                self.inbox.remove(message)\n",
    "        \n",
    "        return responses[0] if responses else None\n",
    "\n",
    "# --------------------------\n",
    "# Registry with LLM Routing\n",
    "# --------------------------\n",
    "\n",
    "class AgentRegistry:\n",
    "    \"\"\"Central registry for agent discovery and management with LLM-based routing\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatVertexAI, heartbeat_timeout: int = 300):\n",
    "        self.agents: Dict[str, Dict[str, Any]] = {}\n",
    "        self.heartbeat_timeout = heartbeat_timeout\n",
    "        self.llm = llm\n",
    "        \n",
    "        # Enhanced LLM prompt for agent matching\n",
    "        self.routing_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert at matching tasks to agent capabilities. Analyze the task description and available agents to determine the best match.\n",
    "\n",
    "Available Agents:\n",
    "{agents}\n",
    "\n",
    "Instructions:\n",
    "1. Match the task to agent capabilities, data sources, and query types\n",
    "2. Consider keywords like \"users\", \"engagement\", \"countries\", \"transactions\"\n",
    "3. Return ONLY the exact agent name that best matches\n",
    "4. If multiple agents could work, pick the most specialized one\n",
    "5. If no good match exists, return \"NO_MATCH\"\n",
    "\n",
    "Examples:\n",
    "- \"top 5 users by engagement\" → look for agents with user/engagement data\n",
    "- \"countries by transaction count\" → look for agents with transaction/country data\n",
    "- \"sales analysis\" → look for agents with sales data\"\"\"),\n",
    "            (\"human\", \"Task: {task}\")\n",
    "        ])\n",
    "        \n",
    "    def register_agent(self, mcp_wrapper: MCPWrapper, endpoint: Optional[str] = None):\n",
    "        \"\"\"Register an agent in the registry\"\"\"\n",
    "        self.agents[mcp_wrapper.agent_name] = {\n",
    "            \"description\": mcp_wrapper.agent_description,\n",
    "            \"capabilities\": [cap.dict() for cap in mcp_wrapper.capabilities],\n",
    "            \"data_sources\": mcp_wrapper.data_sources,\n",
    "            \"query_types\": mcp_wrapper.query_types,\n",
    "            \"endpoint\": endpoint,\n",
    "            \"last_heartbeat\": datetime.now(),\n",
    "            \"wrapper\": mcp_wrapper,\n",
    "            \"active\": True\n",
    "        }\n",
    "        \n",
    "    def update_heartbeat(self, agent_name: str):\n",
    "        \"\"\"Update the last active timestamp for an agent\"\"\"\n",
    "        if agent_name in self.agents:\n",
    "            self.agents[agent_name][\"last_heartbeat\"] = datetime.now()\n",
    "            self.agents[agent_name][\"active\"] = True\n",
    "            \n",
    "    def check_agent_online(self, agent_name: str) -> bool:\n",
    "        \"\"\"Check if an agent is currently online\"\"\"\n",
    "        agent = self.agents.get(agent_name)\n",
    "        if not agent:\n",
    "            return False\n",
    "        return (datetime.now() - agent[\"last_heartbeat\"]).total_seconds() < self.heartbeat_timeout\n",
    "        \n",
    "    def find_best_agent_for_task(self, task_description: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Use LLM to find the best agent for a task\n",
    "        Returns agent name or None if no suitable agent found\n",
    "        \"\"\"\n",
    "        # Format agent information for the prompt with detailed capabilities\n",
    "        agents_info = []\n",
    "        for name, details in self.agents.items():\n",
    "            if not self.check_agent_online(name):\n",
    "                continue\n",
    "            \n",
    "            # Build detailed agent description\n",
    "            agent_desc = []\n",
    "            agent_desc.append(f\"Agent: {name}\")\n",
    "            agent_desc.append(f\"Description: {details['description']}\")\n",
    "            \n",
    "            if details['data_sources']:\n",
    "                agent_desc.append(f\"Data Sources: {', '.join(details['data_sources'])}\")\n",
    "            if details['query_types']:\n",
    "                agent_desc.append(f\"Query Types: {', '.join(details['query_types'])}\")\n",
    "                \n",
    "            capabilities = [cap['name'] for cap in details['capabilities']]\n",
    "            agent_desc.append(f\"Capabilities: {', '.join(capabilities)}\")\n",
    "            \n",
    "            last_active_mins = (datetime.now() - details['last_heartbeat']).total_seconds() / 60\n",
    "            agent_desc.append(f\"Status: ONLINE (last active {last_active_mins:.1f} minutes ago)\")\n",
    "            \n",
    "            agents_info.append('\\n'.join(agent_desc))\n",
    "        \n",
    "        if not agents_info:\n",
    "            print(\"DEBUG: No online agents found\")\n",
    "            return None\n",
    "            \n",
    "        agents_text = '\\n\\n'.join(agents_info)\n",
    "        print(f\"DEBUG: Sending to LLM:\\nTask: {task_description}\\nAgents:\\n{agents_text}\")\n",
    "        \n",
    "        # Get LLM routing\n",
    "        try:\n",
    "            chain = self.routing_prompt | self.llm | StrOutputParser()\n",
    "            recommended_agent = chain.invoke({\n",
    "                \"agents\": agents_text, \n",
    "                \"task\": task_description\n",
    "            }).strip()\n",
    "            \n",
    "            print(f\"DEBUG: LLM recommended: '{recommended_agent}'\")\n",
    "            \n",
    "            # Validate the routing\n",
    "            if recommended_agent == \"NO_MATCH\" or recommended_agent not in self.agents:\n",
    "                print(f\"DEBUG: No valid match found. Available agents: {list(self.agents.keys())}\")\n",
    "                return None\n",
    "                \n",
    "            return recommended_agent\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"DEBUG: Error in LLM routing: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def route_task(self, task_description: str) -> Optional[ModelContext]:\n",
    "        \"\"\"\n",
    "        Automated task routing\n",
    "        1. Finds best agent\n",
    "        2. Creates execution context\n",
    "        3. Returns result context\n",
    "        \"\"\"\n",
    "        agent_name = self.find_best_agent_for_task(task_description)\n",
    "        if not agent_name:\n",
    "            return None\n",
    "            \n",
    "        # Create and execute context\n",
    "        context = ModelContext(\n",
    "            session_id=str(uuid.uuid4()),\n",
    "            timestamp=datetime.now(),\n",
    "            context_data={\n",
    "                \"question\": task_description,\n",
    "                \"max_attempts\": 3\n",
    "            },\n",
    "            target_agents=[agent_name]\n",
    "        )\n",
    "        \n",
    "        wrapper = self.agents[agent_name][\"wrapper\"]\n",
    "        return wrapper.execute(context)\n",
    "    \n",
    "    def discover_agents(self) -> List[str]:\n",
    "        \"\"\"Discover all registered agents\"\"\"\n",
    "        return list(self.agents.keys())\n",
    "    \n",
    "    def get_agent(self, agent_name: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Get agent information\"\"\"\n",
    "        return self.agents.get(agent_name)\n",
    "    \n",
    "    def get_agent_wrapper(self, agent_name: str) -> Optional[MCPWrapper]:\n",
    "        \"\"\"Get agent wrapper for direct execution\"\"\"\n",
    "        agent_info = self.agents.get(agent_name)\n",
    "        return agent_info[\"wrapper\"] if agent_info else None\n",
    "\n",
    "# --------------------------\n",
    "# Test Cases\n",
    "# --------------------------\n",
    "\n",
    "def test_llm_routing():\n",
    "    \"\"\"Test LLM-based agent routing\"\"\"\n",
    "    print(\"\\n=== Testing LLM Routing ===\")\n",
    "    \n",
    "    tasks = [\n",
    "        \"Give me a list of top 5 users by engagement time\",\n",
    "        \"Show me the top 5 countries by transaction count\"\n",
    "    ]\n",
    "    \n",
    "    for task in tasks:\n",
    "        print(f\"\\nTask: {task}\")\n",
    "        best_agent = registry.find_best_agent_for_task(task)\n",
    "        if best_agent:\n",
    "            print(f\"✅ Recommended agent: {best_agent}\")\n",
    "            \n",
    "            # Execute the task\n",
    "            print(\"Executing task...\")\n",
    "            result = registry.route_task(task)\n",
    "            if result:\n",
    "                print(f\"Status: {result.context_data['status']}\")\n",
    "                if result.context_data['status'] == 'success':\n",
    "                    result_str = str(result.context_data['result'])\n",
    "                    print(f\"Result preview: {result_str[:200]}{'...' if len(result_str) > 200 else ''}\")\n",
    "                else:\n",
    "                    print(f\"Error: {result.context_data['result']}\")\n",
    "        else:\n",
    "            print(\"❌ No suitable agent found\")\n",
    "\n",
    "def test_heartbeat_system():\n",
    "    \"\"\"Test agent heartbeat monitoring\"\"\"\n",
    "    print(\"\\n=== Testing Heartbeat System ===\")\n",
    "    \n",
    "    # Check initial status\n",
    "    print(\"\\nAgent statuses:\")\n",
    "    for name in registry.agents:\n",
    "        status = \"ONLINE\" if registry.check_agent_online(name) else \"OFFLINE\"\n",
    "        last_seen = registry.agents[name][\"last_heartbeat\"].strftime('%H:%M:%S')\n",
    "        print(f\"- {name}: {status} (last seen {last_seen})\")\n",
    "    \n",
    "    # Simulate agent going offline\n",
    "    print(\"\\nSimulating Spanner agent going offline...\")\n",
    "    offline_time = datetime.now() - timedelta(seconds=400)\n",
    "    registry.agents[\"SpannerSQLAgent\"][\"last_heartbeat\"] = offline_time\n",
    "    \n",
    "    # Verify routing skips offline agents\n",
    "    task = \"Get transaction counts by country\"\n",
    "    print(f\"\\nRouting task: {task}\")\n",
    "    best_agent = registry.find_best_agent_for_task(task)\n",
    "    print(f\"Selected agent: {best_agent}\")\n",
    "    \n",
    "    # Reset agent status\n",
    "    registry.update_heartbeat(\"SpannerSQLAgent\")\n",
    "\n",
    "\n",
    "def test_a2a_communication():\n",
    "    \"\"\"Test agent-to-agent communication\"\"\"\n",
    "    print(\"\\n=== Testing Agent-to-Agent Communication ===\")\n",
    "    \n",
    "    # Create A2A wrappers\n",
    "    spanner_a2a = A2AWrapper(spanner_mcp)\n",
    "    bq_a2a = A2AWrapper(bq_mcp)\n",
    "    \n",
    "    # Test message sending\n",
    "    print(\"\\n1. Testing message sending between agents\")\n",
    "    \n",
    "    # Spanner agent sends a message to BigQuery agent\n",
    "    message = spanner_a2a.send_message(\n",
    "        recipients=[\"BigQuerySQLAgent\"],\n",
    "        content={\n",
    "            \"request_type\": \"data_validation\",\n",
    "            \"query\": \"Can you validate user engagement data for user_id '6c3dbd5cb2393a74d1b5d1fc3289f4b92deea4f92b9b2994399aabf172c500d5'?\",\n",
    "            \"context\": \"Cross-referencing transaction data with engagement metrics\"\n",
    "        },\n",
    "        requires_response=True\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Message sent from {message.sender} to {message.recipients}\")\n",
    "    print(f\"   Message ID: {message.message_id}\")\n",
    "    print(f\"   Content: {message.content['request_type']}\")\n",
    "    \n",
    "    # BigQuery agent receives the message\n",
    "    bq_a2a.receive_message(message)\n",
    "    print(f\"✅ Message received by BigQuerySQLAgent\")\n",
    "    print(f\"   Inbox size: {len(bq_a2a.inbox)}\")\n",
    "    \n",
    "    # Process messages\n",
    "    print(\"\\n2. Processing messages\")\n",
    "    response = bq_a2a.process_messages()\n",
    "    \n",
    "    if response:\n",
    "        print(f\"✅ Response generated by {response.sender}\")\n",
    "        print(f\"   Response to: {response.recipients}\")\n",
    "        print(f\"   Response content preview: {str(response.content)[:100]}...\")\n",
    "    else:\n",
    "        print(\"❌ No response generated\")\n",
    "\n",
    "def test_advanced_a2a_scenarios():\n",
    "    \"\"\"Test advanced agent-to-agent scenarios\"\"\"\n",
    "    print(\"\\n=== Testing Advanced A2A Scenarios ===\")\n",
    "    \n",
    "    # Create A2A wrappers\n",
    "    spanner_a2a = A2AWrapper(spanner_mcp)\n",
    "    bq_a2a = A2AWrapper(bq_mcp)\n",
    "    \n",
    "    print(\"\\n1. Testing data correlation scenario\")\n",
    "    \n",
    "    # Scenario: Find users with high engagement but low transaction counts\n",
    "    correlation_message = spanner_a2a.send_message(\n",
    "        recipients=[\"BigQuerySQLAgent\"],\n",
    "        content={\n",
    "            \"request_type\": \"data_correlation\",\n",
    "            \"question\": \"Get top 10 users by engagement time\",\n",
    "            \"purpose\": \"Will cross-reference with transaction data\"\n",
    "        },\n",
    "        requires_response=True\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Correlation request sent to BigQuery agent\")\n",
    "    \n",
    "    # BigQuery processes the request\n",
    "    bq_a2a.receive_message(correlation_message)\n",
    "    engagement_response = bq_a2a.process_messages()\n",
    "    \n",
    "    if engagement_response:\n",
    "        print(\"✅ Engagement data retrieved\")\n",
    "        \n",
    "        # Spanner agent uses this data to find patterns\n",
    "        follow_up_context = ModelContext(\n",
    "            session_id=str(uuid.uuid4()),\n",
    "            timestamp=datetime.now(),\n",
    "            context_data={\n",
    "                \"question\": \"Show transaction counts for users with high engagement\",\n",
    "                \"context_data\": engagement_response.content\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        spanner_result = spanner_mcp.execute(follow_up_context)\n",
    "        print(f\"✅ Cross-reference analysis completed\")\n",
    "        print(f\"   Status: {spanner_result.context_data['status']}\")\n",
    "    \n",
    "    print(\"\\n2. Testing message expiration\")\n",
    "    \n",
    "    # Create message with short expiration\n",
    "    expired_message = A2AMessage(\n",
    "        message_id=str(uuid.uuid4()),\n",
    "        sender=\"TestAgent\",\n",
    "        recipients=[\"SpannerSQLAgent\"],\n",
    "        content={\"test\": \"This message should expire\"},\n",
    "        expiration=datetime.now() - timedelta(seconds=1)  \n",
    "    )\n",
    "    \n",
    "    spanner_a2a.receive_message(expired_message)\n",
    "    print(f\"✅ Expired message added to inbox (size: {len(spanner_a2a.inbox)})\")\n",
    "    \n",
    "    spanner_a2a.process_messages()\n",
    "    print(f\"✅ After processing: inbox size: {len(spanner_a2a.inbox)}\")\n",
    "    \n",
    "    print(\"\\n3. Testing multi-agent broadcast\")\n",
    "    \n",
    "    # Create a broadcast message\n",
    "    broadcast_message = bq_a2a.send_message(\n",
    "        recipients=[\"SpannerSQLAgent\"],\n",
    "        content={\n",
    "            \"broadcast_type\": \"system_status\",\n",
    "            \"message\": \"System maintenance scheduled\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        },\n",
    "        requires_response=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Broadcast message created\")\n",
    "    print(f\"   Recipients: {broadcast_message.recipients}\")\n",
    "    print(f\"   Requires response: {broadcast_message.requires_response}\")\n",
    "\n",
    "def test_registry_management():\n",
    "    \"\"\"Test registry management functions\"\"\"\n",
    "    print(\"\\n=== Testing Registry Management ===\")\n",
    "    \n",
    "    print(\"\\n1. Agent Discovery\")\n",
    "    agents = registry.discover_agents()\n",
    "    print(f\"✅ Discovered agents: {agents}\")\n",
    "    \n",
    "    print(\"\\n2. Agent Details\")\n",
    "    for agent_name in agents:\n",
    "        agent_info = registry.get_agent(agent_name)\n",
    "        if agent_info:\n",
    "            print(f\"\\n{agent_name}:\")\n",
    "            print(f\"   Description: {agent_info['description']}\")\n",
    "            print(f\"   Data Sources: {agent_info['data_sources']}\")\n",
    "            print(f\"   Query Types: {agent_info['query_types']}\")\n",
    "            print(f\"   Online: {registry.check_agent_online(agent_name)}\")\n",
    "    \n",
    "    print(\"\\n3. Capability Matching\")\n",
    "    test_queries = [\n",
    "        \"Find users with most transactions\",\n",
    "        \"Analyze engagement patterns over time\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        best_agent = registry.find_best_agent_for_task(query)\n",
    "        print(f\"   '{query}' → {best_agent or 'No match'}\")\n",
    "\n",
    "def test_error_handling():\n",
    "    \"\"\"Test error handling scenarios\"\"\"\n",
    "    print(\"\\n=== Testing Error Handling ===\")\n",
    "    \n",
    "    print(\"\\n1. Invalid SQL query handling\")\n",
    "    error_context = ModelContext(\n",
    "        session_id=str(uuid.uuid4()),\n",
    "        timestamp=datetime.now(),\n",
    "        context_data={\n",
    "            \"question\": \"SELECT * FROM nonexistent_table_xyz\",\n",
    "            \"max_attempts\": 1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = spanner_mcp.execute(error_context)\n",
    "        print(f\"✅ Error handled gracefully\")\n",
    "        print(f\"   Status: {result.context_data['status']}\")\n",
    "        print(f\"   Error message: {result.context_data['result'][:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unhandled error: {e}\")\n",
    "    \n",
    "    print(\"\\n2. Offline agent handling\")\n",
    "    # Temporarily mark agent as offline\n",
    "    original_heartbeat = registry.agents[\"SpannerSQLAgent\"][\"last_heartbeat\"]\n",
    "    registry.agents[\"SpannerSQLAgent\"][\"last_heartbeat\"] = datetime.now() - timedelta(seconds=400)\n",
    "    \n",
    "    task_result = registry.route_task(\"Get transaction data\")\n",
    "    if task_result is None:\n",
    "        print(\"✅ Offline agent correctly excluded from routing\")\n",
    "    else:\n",
    "        print(\"❌ Offline agent was still used\")\n",
    "    \n",
    "    # Restore agent status\n",
    "    registry.agents[\"SpannerSQLAgent\"][\"last_heartbeat\"] = original_heartbeat\n",
    "\n",
    "# --------------------------\n",
    "# Main Execution\n",
    "# --------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load existing agents\n",
    "    def load_agent(agent_file: str):\n",
    "        \"\"\"Dynamically load an agent module\"\"\"\n",
    "        module_name = Path(agent_file).stem\n",
    "        spec = importlib.util.spec_from_file_location(module_name, agent_file)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        sys.modules[module_name] = module\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "\n",
    "    try:\n",
    "        spanner_agent = load_agent(\"spanner_agent.py\")\n",
    "        bq_agent = load_agent(\"bq_agent.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading agents: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Initialize wrappers with detailed metadata\n",
    "    spanner_mcp = MCPWrapper(\n",
    "        agent_instance=spanner_agent,\n",
    "        agent_name=\"SpannerSQLAgent\",\n",
    "        agent_description=\"Generates and executes Google Cloud Spanner SQL queries for transactional data\",\n",
    "        data_sources=[\"transactions\", \"users\", \"countries\", \"payments\", \"orders\"],\n",
    "        query_types=[\"aggregation\", \"filtering\", \"grouping\", \"joins\", \"analytics\"]\n",
    "    )\n",
    "    \n",
    "    bq_mcp = MCPWrapper(\n",
    "        agent_instance=bq_agent,\n",
    "        agent_name=\"BigQuerySQLAgent\", \n",
    "        agent_description=\"Generates and executes BigQuery SQL queries for analytics and reporting\",\n",
    "        data_sources=[\"user_engagement\", \"web_analytics\", \"logs\", \"events\", \"metrics\"],\n",
    "        query_types=[\"analytics\", \"reporting\", \"time_series\", \"aggregation\", \"data_warehouse\"]\n",
    "    )\n",
    "\n",
    "    # Initialize registry with LLM\n",
    "    registry = AgentRegistry(llm=llm, heartbeat_timeout=300)\n",
    "    registry.register_agent(spanner_mcp)\n",
    "    registry.register_agent(bq_mcp)\n",
    "\n",
    "    # Run tests\n",
    "    test_llm_routing()\n",
    "    test_a2a_communication()\n",
    "    test_advanced_a2a_scenarios()\n",
    "    test_heartbeat_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
